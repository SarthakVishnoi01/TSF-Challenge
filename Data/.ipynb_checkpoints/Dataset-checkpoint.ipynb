{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download any package here\n",
    "# # Install a pip package in the current Jupyter kernel\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "from datetime import timedelta, date\n",
    "from wwo_hist import retrieve_hist_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8472 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>government_id</th>\n",
       "      <th>diagnosed_date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>detected_city</th>\n",
       "      <th>detected_district</th>\n",
       "      <th>detected_state</th>\n",
       "      <th>current_status</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KL-TS-P1</td>\n",
       "      <td>30/01/2020</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>Thrissur</td>\n",
       "      <td>Thrissur</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>Travelled from Wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KL-AL-P1</td>\n",
       "      <td>02/02/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>Travelled from Wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KL-KS-P1</td>\n",
       "      <td>03/02/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kasaragod</td>\n",
       "      <td>Kasaragod</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>Travelled from Wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL-P1</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>East Delhi (Mayur Vihar)</td>\n",
       "      <td>East Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>Travelled from Austria, Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TS-P1</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>Travelled from Dubai to Bangalore on 20th Feb,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  government_id diagnosed_date  age gender             detected_city  \\\n",
       "0      KL-TS-P1     30/01/2020   20      F                  Thrissur   \n",
       "1      KL-AL-P1     02/02/2020  NaN    NaN                 Alappuzha   \n",
       "2      KL-KS-P1     03/02/2020  NaN    NaN                 Kasaragod   \n",
       "3         DL-P1     02/03/2020   45      M  East Delhi (Mayur Vihar)   \n",
       "4         TS-P1     02/03/2020   24      M                 Hyderabad   \n",
       "\n",
       "  detected_district detected_state current_status  \\\n",
       "0          Thrissur         Kerala      Recovered   \n",
       "1         Alappuzha         Kerala      Recovered   \n",
       "2         Kasaragod         Kerala      Recovered   \n",
       "3        East Delhi          Delhi      Recovered   \n",
       "4         Hyderabad      Telangana      Recovered   \n",
       "\n",
       "                                               notes  \n",
       "0                               Travelled from Wuhan  \n",
       "1                               Travelled from Wuhan  \n",
       "2                               Travelled from Wuhan  \n",
       "3                      Travelled from Austria, Italy  \n",
       "4  Travelled from Dubai to Bangalore on 20th Feb,...  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the individual data\n",
    "data1 = pd.read_csv('IndividualDetails.csv')\n",
    "# print(data.shape)\n",
    "# data.head()\n",
    "# Deleting id, nationality, status_change_date\n",
    "data = data1.drop(['id', 'nationality', 'status_change_date'], axis=1)\n",
    "# data.head()\n",
    "rows = data.shape[0]\n",
    "columns = data.shape[1]\n",
    "print(rows, columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alappuzha'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['detected_city'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Making a list of foreign cities and countries where the person might have contracted the virus\n",
    "# foreignList = ['Wuhan', 'Italy', 'Austria', 'Dubai', 'Iran', 'Malaysia', 'Doha']\n",
    "# For ARIMA we can also make age brackets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>government_id</th>\n",
       "      <th>diagnosed_date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>detected_city</th>\n",
       "      <th>detected_district</th>\n",
       "      <th>detected_state</th>\n",
       "      <th>current_status</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KL-TS-P1</td>\n",
       "      <td>30/01/2020</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>Thrissur</td>\n",
       "      <td>Thrissur</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>Travelled from Wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KL-AL-P1</td>\n",
       "      <td>02/02/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>Travelled from Wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KL-KS-P1</td>\n",
       "      <td>03/02/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kasaragod</td>\n",
       "      <td>Kasaragod</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>Travelled from Wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL-P1</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>East Delhi (Mayur Vihar)</td>\n",
       "      <td>East Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>Travelled from Austria, Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TS-P1</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>Travelled from Dubai to Bangalore on 20th Feb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>04/03/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Agra</td>\n",
       "      <td>Agra</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Hospitalized</td>\n",
       "      <td>Family members of P4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  government_id diagnosed_date  age gender             detected_city  \\\n",
       "0      KL-TS-P1     30/01/2020   20      F                  Thrissur   \n",
       "1      KL-AL-P1     02/02/2020  NaN    NaN                 Alappuzha   \n",
       "2      KL-KS-P1     03/02/2020  NaN    NaN                 Kasaragod   \n",
       "3         DL-P1     02/03/2020   45      M  East Delhi (Mayur Vihar)   \n",
       "4         TS-P1     02/03/2020   24      M                 Hyderabad   \n",
       "5           NaN     04/03/2020  NaN      M                      Agra   \n",
       "\n",
       "  detected_district detected_state current_status  \\\n",
       "0          Thrissur         Kerala      Recovered   \n",
       "1         Alappuzha         Kerala      Recovered   \n",
       "2         Kasaragod         Kerala      Recovered   \n",
       "3        East Delhi          Delhi      Recovered   \n",
       "4         Hyderabad      Telangana      Recovered   \n",
       "5              Agra  Uttar Pradesh   Hospitalized   \n",
       "\n",
       "                                               notes  \n",
       "0                               Travelled from Wuhan  \n",
       "1                               Travelled from Wuhan  \n",
       "2                               Travelled from Wuhan  \n",
       "3                      Travelled from Austria, Italy  \n",
       "4  Travelled from Dubai to Bangalore on 20th Feb,...  \n",
       "5                               Family members of P4  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping rows without districts\n",
    "for index,row in data.iterrows():\n",
    "    if(not(row['detected_district'] == row['detected_district'])):\n",
    "        data.drop(index, inplace=True)\n",
    "    elif((row['detected_district'] == 'Italians*') or (row['detected_district'] == 'Evacuees') or (row['detected_district'] == 'Gujarat*')):\n",
    "        data.drop(index, inplace=True)\n",
    "data.reset_index(inplace = True, drop = True)\n",
    "data.head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a dictionary of districts whose csv files are named something else\n",
    "diffDist = {}\n",
    "diffDist['Ahmadnagar'] = 'Ahmednagar'\n",
    "diffDist['Ahmadabad'] = 'Ahmedabad'\n",
    "diffDist['Ballari'] = 'Bellary'\n",
    "diffDist['Bagalkote'] = 'Bagalkot'\n",
    "diffDist['Bhivani'] = 'Bhiwani'\n",
    "diffDist['Bara Banki'] = 'Bara+Banki'\n",
    "diffDist['Bengaluru Rural'] = 'Bengaluru+Rural'\n",
    "diffDist['Bhadradri Kothagudem'] = 'Bhadradri+Kothagudem'\n",
    "diffDist['Charki Dadri'] = 'Charki+Dadri'\n",
    "diffDist['Chikkaballapura'] = 'Chikkaballapur'\n",
    "diffDist['Chota Udaipur'] = 'Chota+Udaipur'\n",
    "diffDist['Dakshina Kannada'] = 'Dakshina+Kannada'\n",
    "diffDist['East Delhi'] = 'East+Delhi'\n",
    "diffDist['East Godavari'] = 'East+Godavari'\n",
    "diffDist['Fatehgarh Sahib'] = 'Fatehgarh+Sahib'\n",
    "diffDist['Gautam Buddha Nagar'] = 'Gautam+Buddh+Nagar'\n",
    "diffDist['Gir Somnath'] = 'Gir'\n",
    "diffDist['Goalaghat'] = 'Golaghat'\n",
    "diffDist['Gondiya'] = 'Gondia'\n",
    "diffDist['Gurugram'] = 'Gurgaon'\n",
    "diffDist['Hatras'] = 'Hathras'\n",
    "diffDist['Imphal West'] = 'Imphal'\n",
    "diffDist['Jagitial'] = 'Jagtial'\n",
    "diffDist['Jogulamba Gadwal'] = 'Gadwal'\n",
    "diffDist['Kachchh'] = 'Kutch'\n",
    "diffDist['Kamrup Metropolitan'] = 'Kamrup'\n",
    "diffDist['Kancheepuram'] = 'Kanchipuram'\n",
    "diffDist['Kanniyakumari'] = 'Kanyakumari'\n",
    "diffDist['Kanpur Nagar'] = 'Kanpur'\n",
    "diffDist['Mahesana'] = 'Mehsana'\n",
    "diffDist['Mahabubnagar'] = 'Mahbubnagar'\n",
    "diffDist['Mahrajganj'] = 'Maharajganj'\n",
    "diffDist['Medchal Malkajgiri'] = 'Medchal'\n",
    "diffDist['Medinipur East'] = 'Midnapore'\n",
    "diffDist['Mumbai Suburban'] = 'Mumbai+Suburban'\n",
    "diffDist['New Delhi'] = 'New+Delhi'\n",
    "diffDist['North 24 Parganas'] = 'Barasat'\n",
    "diffDist['North and Middle Andaman'] = 'Mayabunder'\n",
    "diffDist['North Delhi'] = 'North+Delhi'\n",
    "diffDist['North East Delhi'] = 'North+East+Delhi'\n",
    "diffDist['North Goa'] = 'North+Goa'\n",
    "diffDist['North West Delhi'] = 'North+West+Delhi'\n",
    "diffDist['Panch Mahals'] = 'Godhra'\n",
    "diffDist['Pauri Garhwal'] = 'Pauri'\n",
    "diffDist['Rae Bareli'] = 'Rae+Bareli'\n",
    "diffDist['Ranga Reddy'] = 'Shamshabad'\n",
    "diffDist['S.A.S. Nagar'] = 'Mohali'\n",
    "diffDist['S.P.S. Nellore'] = 'Nellore'\n",
    "diffDist['Sabar Kantha'] = 'Himatnagar'\n",
    "diffDist['Shahid Bhagat Singh Nagar'] = 'Nawanshahr'\n",
    "diffDist['South 24 Parganas'] = 'Alipore'\n",
    "diffDist['South Andaman'] = 'Port+Blair'\n",
    "diffDist['South Delhi'] = 'South+Delhi'\n",
    "diffDist['South West Delhi'] = 'South+West+Delhi'\n",
    "diffDist['South Salmara Mancachar'] = 'Hatsingimari'\n",
    "diffDist['The Nilgiris'] = 'Udhagamandalam'\n",
    "diffDist['Thoothukkudi'] = 'Thoothukudi'\n",
    "diffDist['Udham Singh Nagar'] = 'Rudrapur'\n",
    "diffDist['Uttara Kannada'] = 'Bhatkal'\n",
    "diffDist['Warangal Urban'] = 'Warangal'\n",
    "diffDist['West Delhi'] = 'West+Delhi'\n",
    "diffDist['West Godavari'] = 'West+Godavari'\n",
    "diffDist['Y.S.R.'] = 'Kadapa'\n",
    "len(diffDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating an empty data fram which would contain details for temperature and RH\n",
    "# rows = data.shape[0]\n",
    "# tempRH = np.zeros((rows, 30))\n",
    "# for index,row in data.iterrows():\n",
    "#     print(index)\n",
    "#     if((row['detected_district'] in diffDist)):\n",
    "#         tempDist = diffDist[row['detected_district']]\n",
    "#     else:\n",
    "#         tempDist = row['detected_district']\n",
    "#     print(tempDist)\n",
    "#     tempData = pd.read_csv('./Weather/' + tempDist + '.csv')\n",
    "#     date_str1 = row['diagnosed_date']\n",
    "#     date_object1 = datetime.strptime(date_str1, '%d-%m-%Y').date()\n",
    "#     for index_,row_ in tempData.iterrows():\n",
    "#         date_str2 = row_['date_time']\n",
    "#         date_object2 = datetime.strptime(date_str2, '%Y-%m-%d').date()\n",
    "#         if(date_object1 == date_object2):\n",
    "# #             print(\"Hi\")\n",
    "#             for i in range(15):\n",
    "#                 tempRH[index,i] = tempData['FeelsLikeC'][index_-i]\n",
    "#                 tempRH[index,i+15] = tempData['humidity'][index_-i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4769, 39)\n"
     ]
    }
   ],
   "source": [
    "# # Concatinating two data frames\n",
    "# cols = ['Temp_0', 'Temp_1', 'Temp_2', 'Temp_3', 'Temp_4', 'Temp_5', 'Temp_6', 'Temp_7', 'Temp_8', 'Temp_9', 'Temp_10', 'Temp_11', 'Temp_12', 'Temp_13', 'Temp_14', 'RH_0', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7', 'RH_8', 'RH_9', 'RH_10', 'RH_11', 'RH_12', 'RH_13', 'RH_14']\n",
    "# tempRHdf = pd.DataFrame(data=tempRH, columns=cols)\n",
    "# result = pd.concat([data, tempRHdf], axis=1, sort=False)\n",
    "# result.head()\n",
    "# # result.to_csv('individualDetailsModified.csv',index=False)\n",
    "# print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # places = ['Wuhan', 'Austria', 'Italy', 'Germany', 'Dubai', 'Mecca', 'Oman', 'USA', 'US', 'UK', 'Thailand', 'Iran', 'Qatar', 'Middle East', 'Singapore', 'Philippines', 'Mecca', 'Saudi Arabia', 'Japan', 'Spain', ]\n",
    "# china = ['China', 'Wuhan']\n",
    "# usa = ['USA', 'US', 'New York', 'San Francisco', 'California']\n",
    "# middleEast = ['Dubai', 'Abu Dhabi', 'UAE', 'Mecca', 'Saudi Arabia', 'Middle East', 'Doha', 'Qatar', 'Kuwait', 'Bahrain', 'Iran', 'Oman', 'Saudi', 'Finland']\n",
    "# europeExItaly = ['UK', 'France', 'Austria', 'Germany', 'London', 'Spain', 'Paris', 'Russia']\n",
    "# italy = ['Italy', 'Rome']\n",
    "# southEastAsia = ['Singapore', 'Thailand', 'Philippines', 'Malaysia', 'Bangkok', 'Phuket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extracting information from notes\n",
    "# print(rows)\n",
    "# result['notes'] = result['notes'].str.replace(',',' ')\n",
    "# result['notes'] = result['notes'].str.replace('-',' ')\n",
    "# result['notes'] = result['notes'].str.replace(';',' ')\n",
    "# result['notes'] = result['notes'].str.replace('.',' ')\n",
    "# # Making a numpy barray for storing these binary variables, can add details for jamat when they come\n",
    "# places = np.zeros((rows,6))\n",
    "# for i in range (rows):\n",
    "#     if(not(isinstance(result['notes'][i],str))):\n",
    "#         continue\n",
    "#     words = (result['notes'][i]).split()\n",
    "#     for place in china:\n",
    "#         if place in words:\n",
    "#             places[i,0] = 1\n",
    "#     for place in usa:\n",
    "#         if place in words:\n",
    "#             places[i,1] = 1\n",
    "#     for place in middleEast:\n",
    "#         if place in words:\n",
    "#             places[i,2] = 1\n",
    "#     for place in europeExItaly:\n",
    "#         if place in words:\n",
    "#             places[i,3] = 1\n",
    "#     for place in italy:\n",
    "#         if place in words:\n",
    "#             places[i,4] = 1\n",
    "#     for place in southEastAsia:\n",
    "#         if place in words:\n",
    "#             places[i,5] = 1\n",
    "# colPlaces = ['China', 'USA', 'Middle_East', 'Europe_Ex_Italy', 'Italy', 'South_East_Asia']\n",
    "# placesDF = pd.DataFrame(data=places, columns=colPlaces)      \n",
    "# resultWithPlaces = pd.concat([result, placesDF], axis=1, sort=False)\n",
    "# resultWithPlaces = resultWithPlaces.drop(['notes'], axis=1)\n",
    "# print(resultWithPlaces.shape)\n",
    "# print(resultWithPlaces.head())\n",
    "# resultWithPlaces.to_csv('individualDetailsModified.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Status</th>\n",
       "      <th>TT</th>\n",
       "      <th>AN</th>\n",
       "      <th>AP</th>\n",
       "      <th>AR</th>\n",
       "      <th>AS</th>\n",
       "      <th>BR</th>\n",
       "      <th>CH</th>\n",
       "      <th>CT</th>\n",
       "      <th>...</th>\n",
       "      <th>PY</th>\n",
       "      <th>PB</th>\n",
       "      <th>RJ</th>\n",
       "      <th>SK</th>\n",
       "      <th>TN</th>\n",
       "      <th>TG</th>\n",
       "      <th>TR</th>\n",
       "      <th>UP</th>\n",
       "      <th>UT</th>\n",
       "      <th>WB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14-Mar-20</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14-Mar-20</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14-Mar-20</td>\n",
       "      <td>Deceased</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-Mar-20</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-Mar-20</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>07-Apr-20</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>07-Apr-20</td>\n",
       "      <td>Deceased</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>08-Apr-20</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>565</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>08-Apr-20</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>08-Apr-20</td>\n",
       "      <td>Deceased</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Status   TT  AN    AP  AR  AS  BR  CH  CT  ...  PY  PB  RJ  \\\n",
       "0   14-Mar-20  Confirmed   79   0   1.0   0   0   0   0   0  ...   0   1   3   \n",
       "1   14-Mar-20  Recovered    9   0   0.0   0   0   0   0   0  ...   0   0   1   \n",
       "2   14-Mar-20   Deceased    2   0   0.0   0   0   0   0   0  ...   0   0   0   \n",
       "3   15-Mar-20  Confirmed   28   0   0.0   0   0   0   0   0  ...   0   0   1   \n",
       "4   15-Mar-20  Recovered    4   0   0.0   0   0   0   0   0  ...   0   0   2   \n",
       "..        ...        ...  ...  ..   ...  ..  ..  ..  ..  ..  ...  ..  ..  ..   \n",
       "73  07-Apr-20  Recovered   74   0   0.0   0   0   6   2   1  ...   1  10   0   \n",
       "74  07-Apr-20   Deceased   26   0   0.0   0   0   0   0   0  ...   0   1   0   \n",
       "75  08-Apr-20  Confirmed  565   1  34.0   0   0   1   0   0  ...   0   7  40   \n",
       "76  08-Apr-20  Recovered   96   0   1.0   0   0   0   0   0  ...   0   0  20   \n",
       "77  08-Apr-20   Deceased   20   0   0.0   0   0   0   0   0  ...   0   1   1   \n",
       "\n",
       "    SK  TN  TG  TR  UP  UT  WB  \n",
       "0    0   1   1   0  12   0   0  \n",
       "1    0   0   0   0   4   0   0  \n",
       "2    0   0   0   0   0   0   0  \n",
       "3    0   0   2   0   1   0   0  \n",
       "4    0   0   1   0   0   0   0  \n",
       "..  ..  ..  ..  ..  ..  ..  ..  \n",
       "73   0   6   0   0   0   0   3  \n",
       "74   0   1   0   0   0   0   0  \n",
       "75   0  48  49   0  29   4   8  \n",
       "76   0   2   0   0  10   1   0  \n",
       "77   0   1   0   0   1   0   2  \n",
       "\n",
       "[78 rows x 40 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File with timeseries data state wise\n",
    "ts = pd.read_csv('StateWiseDaily.csv')\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['government_id', 'diagnosed_date', 'age', 'gender', 'detected_city',\n",
      "       'detected_district', 'detected_state', 'current_status', 'Temp_0',\n",
      "       'Temp_1', 'Temp_2', 'Temp_3', 'Temp_4', 'Temp_5', 'Temp_6', 'Temp_7',\n",
      "       'Temp_8', 'Temp_9', 'Temp_10', 'Temp_11', 'Temp_12', 'Temp_13',\n",
      "       'Temp_14', 'RH_0', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6',\n",
      "       'RH_7', 'RH_8', 'RH_9', 'RH_10', 'RH_11', 'RH_12', 'RH_13', 'RH_14',\n",
      "       'China', 'USA', 'Middle_East', 'Europe_Ex_Italy', 'Italy',\n",
      "       'South_East_Asia'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# resCols = resultWithPlaces.columns\n",
    "# print(resCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "31\n",
      "Andaman and Nicobar Islands -> 6\n",
      "Andhra Pradesh -> 348\n",
      "Arunachal Pradesh -> 1\n",
      "Assam -> 28\n",
      "Bihar -> 39\n",
      "Chandigarh -> 18\n",
      "Chhattisgarh -> 10\n",
      "Dadra and Nagar Haveli -> 0\n",
      "Delhi -> 44\n",
      "Goa -> 4\n",
      "Gujarat -> 186\n",
      "Haryana -> 153\n",
      "Himachal Pradesh -> 15\n",
      "Jammu and Kashmir -> 76\n",
      "Jharkhand -> 4\n",
      "Karnataka -> 181\n",
      "Kerala -> 345\n",
      "Ladakh -> 14\n",
      "Madhya Pradesh -> 332\n",
      "Maharashtra -> 1133\n",
      "Manipur -> 1\n",
      "Mizoram -> 1\n",
      "Odisha -> 42\n",
      "Puducherry -> 5\n",
      "Punjab -> 106\n",
      "Rajasthan -> 345\n",
      "Tamil Nadu -> 738\n",
      "Telangana -> 176\n",
      "Uttar Pradesh -> 361\n",
      "Uttarakhand -> 29\n",
      "West Bengal -> 27\n"
     ]
    }
   ],
   "source": [
    "# Creating different CSV files for individual analysis with temperature and Humidity\n",
    "# Using individual details, can be used for pooled data analysis in future, see it again\n",
    "states = ['Andaman and Nicobar Islands', 'Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar', 'Chandigarh', 'Chhattisgarh', 'Dadra and Nagar Haveli', 'Delhi', 'Goa', 'Gujarat', 'Haryana', 'Himachal Pradesh', 'Jammu and Kashmir', 'Jharkhand', 'Karnataka', 'Kerala', 'Ladakh', 'Madhya Pradesh', 'Maharashtra', 'Manipur', 'Mizoram', 'Odisha', 'Puducherry', 'Punjab', 'Rajasthan', 'Tamil Nadu', 'Telangana', 'Uttar Pradesh', 'Uttarakhand', 'West Bengal']\n",
    "stateCodes = ['AN', 'AP', 'AR', 'AS', 'BR', 'CH', 'CT', 'DN', 'DL', 'GA', 'GJ', 'HR', 'HP', 'JK', 'JH', 'KA', 'KL', 'LA', 'MP', 'MH', 'MN', 'MZ', 'OR', 'PY', 'PB', 'RJ', 'TN', 'TG', 'UP', 'UT', 'WB']\n",
    "print(len(states))\n",
    "print(len(stateCodes))\n",
    "for state in states:\n",
    "    indexState = states.index(state)\n",
    "    stateCode = stateCodes[indexState]\n",
    "    stateDF = pd.DataFrame(columns=resCols)\n",
    "    for index,row in resultWithPlaces.iterrows():\n",
    "        if(row['detected_state'] == state):\n",
    "            stateDF = stateDF.append(resultWithPlaces.iloc[index,:], ignore_index=True)\n",
    "#             Can use notes for foreign return\n",
    "    stateDF = stateDF.drop(['government_id', 'age', 'gender', 'detected_city', 'detected_district','current_status'], axis=1)\n",
    "    numRows = stateDF.shape[0]\n",
    "#     print(stateDF.head())\n",
    "#     New Cases, recovered, Died\n",
    "    statusState = np.zeros((numRows, 4))\n",
    "    # Fourth one is for lockdown\n",
    "    lockdown_date_str = \"25-03-2020\"\n",
    "    lockdown_date_obj = datetime.strptime(lockdown_date_str, '%d-%m-%Y').date() \n",
    "    for index,row in stateDF.iterrows():\n",
    "        date_str1 = row['diagnosed_date']\n",
    "        date_object1 = datetime.strptime(date_str1, '%d-%m-%Y').date()\n",
    "        for index_,row_ in ts.iterrows():\n",
    "            date_str2 = row_['Date']\n",
    "            date_object2 = datetime.strptime(date_str2, '%d-%b-%y').date()\n",
    "            if(date_object1 == date_object2):\n",
    "                statusState[index,0] = ts.loc[index_,stateCode]\n",
    "                statusState[index,1] = ts.loc[index_+1,stateCode]\n",
    "                statusState[index,2] = ts.loc[index_+2,stateCode]\n",
    "                if(date_object1 >= lockdown_date_obj):\n",
    "                    statusState[index,3] = 1\n",
    "                break\n",
    "                \n",
    "#     Adding this numpy array to stateDF\n",
    "    cols = ['newCases', 'Recovered', 'Deceased', 'Lockdown']\n",
    "    statusStateDF = pd.DataFrame(data=statusState, columns=cols)\n",
    "    stateDF = pd.concat([stateDF, statusStateDF], axis=1, sort=False)\n",
    "#     print(stateDF.shape)\n",
    "    stateDF.to_csv('./TimeSeries_with_Temp/' + state + '.csv',index=False)\n",
    "#     print(\"The state \" + state + \" has \" + str(stateDF.shape[0]) + \" number of COVID-19 cases till 8/4/20.\")\n",
    "    print(state + \" -> \" + str(stateDF.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series data without any explanatory variables, state-wise and total\n",
    "# Data from COVID-19 google drive\n",
    "newRows = int(ts.shape[0]/3)\n",
    "stateDFTScolumns=['NewCases', 'Recovered', 'Deaths', 'Lockdown']    \n",
    "lockdown_date_str = \"25-03-2020\"\n",
    "lockdown_date_obj = datetime.strptime(lockdown_date_str, '%d-%m-%Y').date()\n",
    "for stateCode in stateCodes:\n",
    "    statusStateTS = np.zeros([newRows,4])\n",
    "    dates = []\n",
    "    indexState = stateCodes.index(stateCode)\n",
    "    state = states[indexState]\n",
    "    for index in range(newRows):\n",
    "        dates.append(ts['Date'][3*index])\n",
    "        statusStateTS[index,0] = ts.loc[3*index,stateCode]\n",
    "        statusStateTS[index,1] = ts.loc[3*index+1,stateCode]\n",
    "        statusStateTS[index,2] = ts.loc[3*index+2,stateCode]\n",
    "        date_obj = datetime.strptime(ts['Date'][3*index], '%d-%b-%y').date()\n",
    "        if(date_obj >= lockdown_date_obj):\n",
    "            statusStateTS[index,3] = 1\n",
    "        \n",
    "    datesDF = pd.DataFrame(data=dates, columns=['Date'])    \n",
    "    stateStatusDFTS_temp = pd.DataFrame(data=statusStateTS, columns=stateDFTScolumns)\n",
    "    stateStatusDFTS = pd.concat([datesDF, stateStatusDFTS_temp], axis=1, sort=False)\n",
    "    stateStatusDFTS.to_csv('./TimeSeries/' + state + '.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will need to add time series data for before 15th March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Daily Confirmed</th>\n",
       "      <th>Total Confirmed</th>\n",
       "      <th>Daily Recovered</th>\n",
       "      <th>Total Recovered</th>\n",
       "      <th>Daily Deceased</th>\n",
       "      <th>Total Decease</th>\n",
       "      <th>Lockdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30-Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31-Jan</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-Feb</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02-Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date  Daily Confirmed  Total Confirmed  Daily Recovered  Total Recovered  \\\n",
       "0  30-Jan                1                1                0                0   \n",
       "1  31-Jan                0                1                0                0   \n",
       "2  01-Feb                0                1                0                0   \n",
       "3  02-Feb                1                2                0                0   \n",
       "4  03-Feb                1                3                0                0   \n",
       "\n",
       "   Daily Deceased  Total Decease  Lockdown  \n",
       "0               0              0         0  \n",
       "1               0              0         0  \n",
       "2               0              0         0  \n",
       "3               0              0         0  \n",
       "4               0              0         0  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# India Time series (with lockdown)\n",
    "# Data from COVID-19 India, add lockdown variable in it\n",
    "indiaTS = pd.read_csv('India_Time_Series.csv')\n",
    "indiaTS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guntur: 82\n",
      "Kurnool: 84\n",
      "Ahmadabad: 282\n",
      "Vadodara: 101\n",
      "Bengaluru: 76\n",
      "Kannur: 72\n",
      "Kasaragod: 166\n",
      "Bhopal: 134\n",
      "Indore: 311\n",
      "Mumbai: 1259\n",
      "Pune: 261\n",
      "Thane: 145\n",
      "Jaipur: 341\n",
      "Chennai: 200\n",
      "Coimbatore: 119\n",
      "Erode: 64\n",
      "Tiruppur: 61\n",
      "Hyderabad: 197\n",
      "Agra: 104\n",
      "4059\n"
     ]
    }
   ],
   "source": [
    "# Making Time Series data for districts with more than 100 cases, starting from 15th March\n",
    "\n",
    "# Finding districts with more than 100 cases so far, we'll add Delhi afterwards\n",
    "limit = 60 #Change here for changing the limit of 100\n",
    "os.chdir(r\"C:\\Users\\Sarthak Vishnoi\\TSF-Challenge\\Data\")\n",
    "districtData = pd.read_csv('DistrictWise.csv')\n",
    "districts = []\n",
    "delhi = ['Faridabad', 'Gautam Buddha Nagar', 'Ghaziabad', 'Gurugram']\n",
    "delhiState = ['Delhi']\n",
    "total = 0\n",
    "for index,row in districtData.iterrows():\n",
    "    if(row['Confirmed'] >= limit):\n",
    "        if(not(row['District'] in delhi)):\n",
    "            districts.append(row['District'])\n",
    "            print(row['District'] + \": \" + str(row['Confirmed']))\n",
    "            total += row['Confirmed']\n",
    "print(total)\n",
    "# print(districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Guntur', 'Kurnool', 'Ahmadabad', 'Vadodara', 'Bengaluru', 'Kannur', 'Kasaragod', 'Bhopal', 'Indore', 'Mumbai', 'Pune', 'Thane', 'Jaipur', 'Chennai', 'Coimbatore', 'Erode', 'Tiruppur', 'Hyderabad', 'Agra', 'Delhi', 'Delhi', 'Delhi', 'Delhi', 'Delhi']\n",
      "\n",
      "\n",
      "Retrieving weather data for Guntur\n",
      "\n",
      "\n",
      "Currently retrieving data for Guntur: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.836300\n",
      "Currently retrieving data for Guntur: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.516358\n",
      "Currently retrieving data for Guntur: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.953481\n",
      "Currently retrieving data for Guntur: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.906703\n",
      "\n",
      "\n",
      "export Guntur completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Kurnool\n",
      "\n",
      "\n",
      "Currently retrieving data for Kurnool: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.299925\n",
      "Currently retrieving data for Kurnool: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.597279\n",
      "Currently retrieving data for Kurnool: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.898032\n",
      "Currently retrieving data for Kurnool: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.725636\n",
      "\n",
      "\n",
      "export Kurnool completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Ahmadabad\n",
      "\n",
      "\n",
      "Currently retrieving data for Ahmadabad: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.353312\n",
      "Currently retrieving data for Ahmadabad: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.830565\n",
      "Currently retrieving data for Ahmadabad: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.132631\n",
      "Currently retrieving data for Ahmadabad: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.845069\n",
      "\n",
      "\n",
      "export Ahmadabad completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Vadodara\n",
      "\n",
      "\n",
      "Currently retrieving data for Vadodara: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.342329\n",
      "Currently retrieving data for Vadodara: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.740829\n",
      "Currently retrieving data for Vadodara: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.085339\n",
      "Currently retrieving data for Vadodara: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.964015\n",
      "\n",
      "\n",
      "export Vadodara completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Bengaluru\n",
      "\n",
      "\n",
      "Currently retrieving data for Bengaluru: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.317185\n",
      "Currently retrieving data for Bengaluru: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.583398\n",
      "Currently retrieving data for Bengaluru: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.792171\n",
      "Currently retrieving data for Bengaluru: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.581878\n",
      "\n",
      "\n",
      "export Bengaluru completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Kannur\n",
      "\n",
      "\n",
      "Currently retrieving data for Kannur: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.272878\n",
      "Currently retrieving data for Kannur: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.614557\n",
      "Currently retrieving data for Kannur: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.867495\n",
      "Currently retrieving data for Kannur: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.651886\n",
      "\n",
      "\n",
      "export Kannur completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Kasaragod\n",
      "\n",
      "\n",
      "Currently retrieving data for Kasaragod: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.305500\n",
      "Currently retrieving data for Kasaragod: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.504407\n",
      "Currently retrieving data for Kasaragod: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.757663\n",
      "Currently retrieving data for Kasaragod: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.489603\n",
      "\n",
      "\n",
      "export Kasaragod completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Bhopal\n",
      "\n",
      "\n",
      "Currently retrieving data for Bhopal: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.389213\n",
      "Currently retrieving data for Bhopal: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.765041\n",
      "Currently retrieving data for Bhopal: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.109354\n",
      "Currently retrieving data for Bhopal: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.837151\n",
      "\n",
      "\n",
      "export Bhopal completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Indore\n",
      "\n",
      "\n",
      "Currently retrieving data for Indore: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.356357\n",
      "Currently retrieving data for Indore: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.642039\n",
      "Currently retrieving data for Indore: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.599678\n",
      "Currently retrieving data for Indore: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.400213\n",
      "\n",
      "\n",
      "export Indore completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Mumbai\n",
      "\n",
      "\n",
      "Currently retrieving data for Mumbai: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.261890\n",
      "Currently retrieving data for Mumbai: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.734951\n",
      "Currently retrieving data for Mumbai: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.101001\n",
      "Currently retrieving data for Mumbai: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.931820\n",
      "\n",
      "\n",
      "export Mumbai completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Pune\n",
      "\n",
      "\n",
      "Currently retrieving data for Pune: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.721336\n",
      "Currently retrieving data for Pune: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.161247\n",
      "Currently retrieving data for Pune: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.450439\n",
      "Currently retrieving data for Pune: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.651880\n",
      "\n",
      "\n",
      "export Pune completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Thane\n",
      "\n",
      "\n",
      "Currently retrieving data for Thane: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.987097\n",
      "Currently retrieving data for Thane: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.389159\n",
      "Currently retrieving data for Thane: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.649795\n",
      "Currently retrieving data for Thane: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:07.220778\n",
      "\n",
      "\n",
      "export Thane completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Jaipur\n",
      "\n",
      "\n",
      "Currently retrieving data for Jaipur: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.543464\n",
      "Currently retrieving data for Jaipur: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.287288\n",
      "Currently retrieving data for Jaipur: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.610839\n",
      "Currently retrieving data for Jaipur: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.384599\n",
      "\n",
      "\n",
      "export Jaipur completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Chennai\n",
      "\n",
      "\n",
      "Currently retrieving data for Chennai: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.048131\n",
      "Currently retrieving data for Chennai: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.932675\n",
      "Currently retrieving data for Chennai: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.839023\n",
      "Currently retrieving data for Chennai: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.797971\n",
      "\n",
      "\n",
      "export Chennai completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Coimbatore\n",
      "\n",
      "\n",
      "Currently retrieving data for Coimbatore: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.574795\n",
      "Currently retrieving data for Coimbatore: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.264765\n",
      "Currently retrieving data for Coimbatore: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.147367\n",
      "Currently retrieving data for Coimbatore: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.006609\n",
      "\n",
      "\n",
      "export Coimbatore completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Erode\n",
      "\n",
      "\n",
      "Currently retrieving data for Erode: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.804350\n",
      "Currently retrieving data for Erode: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.790037\n",
      "Currently retrieving data for Erode: from 2020-03-01 to 2020-03-31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (hh:mm:ss.ms) 0:00:05.413287\n",
      "Currently retrieving data for Erode: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.622037\n",
      "\n",
      "\n",
      "export Erode completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Tiruppur\n",
      "\n",
      "\n",
      "Currently retrieving data for Tiruppur: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.021066\n",
      "Currently retrieving data for Tiruppur: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.679727\n",
      "Currently retrieving data for Tiruppur: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.802345\n",
      "Currently retrieving data for Tiruppur: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.823252\n",
      "\n",
      "\n",
      "export Tiruppur completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Hyderabad\n",
      "\n",
      "\n",
      "Currently retrieving data for Hyderabad: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.006946\n",
      "Currently retrieving data for Hyderabad: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.332783\n",
      "Currently retrieving data for Hyderabad: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.127394\n",
      "Currently retrieving data for Hyderabad: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.989798\n",
      "\n",
      "\n",
      "export Hyderabad completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Agra\n",
      "\n",
      "\n",
      "Currently retrieving data for Agra: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.419384\n",
      "Currently retrieving data for Agra: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.380740\n",
      "Currently retrieving data for Agra: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.654508\n",
      "Currently retrieving data for Agra: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.643866\n",
      "\n",
      "\n",
      "export Agra completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Delhi\n",
      "\n",
      "\n",
      "Currently retrieving data for Delhi: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.714496\n",
      "Currently retrieving data for Delhi: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.975003\n",
      "Currently retrieving data for Delhi: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.324586\n",
      "Currently retrieving data for Delhi: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.087503\n",
      "\n",
      "\n",
      "export Delhi completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Delhi\n",
      "\n",
      "\n",
      "Currently retrieving data for Delhi: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.764857\n",
      "Currently retrieving data for Delhi: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.042074\n",
      "Currently retrieving data for Delhi: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.074000\n",
      "Currently retrieving data for Delhi: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.894201\n",
      "\n",
      "\n",
      "export Delhi completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Delhi\n",
      "\n",
      "\n",
      "Currently retrieving data for Delhi: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.986291\n",
      "Currently retrieving data for Delhi: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.271713\n",
      "Currently retrieving data for Delhi: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.165275\n",
      "Currently retrieving data for Delhi: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.647984\n",
      "\n",
      "\n",
      "export Delhi completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Delhi\n",
      "\n",
      "\n",
      "Currently retrieving data for Delhi: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.110804\n",
      "Currently retrieving data for Delhi: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.925533\n",
      "Currently retrieving data for Delhi: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.737473\n",
      "Currently retrieving data for Delhi: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.156767\n",
      "\n",
      "\n",
      "export Delhi completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Delhi\n",
      "\n",
      "\n",
      "Currently retrieving data for Delhi: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.954191\n",
      "Currently retrieving data for Delhi: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.659671\n",
      "Currently retrieving data for Delhi: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.638159\n",
      "Currently retrieving data for Delhi: from 2020-04-01 to 2020-04-12\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.128963\n",
      "\n",
      "\n",
      "export Delhi completed!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting relevant Temperature and Humidity data\n",
    "# Intialisations\n",
    "\n",
    "os.chdir(r\"C:\\Users\\Sarthak Vishnoi\\TSF-Challenge\\Data\\Weather\")\n",
    "frequency=24\n",
    "start_date = '01-JAN-2020'\n",
    "end_date = '12-APR-2020'\n",
    "api_key = '016c031d9643406991194842200504'\n",
    "# api_key = '764936a7a50e4cb694773340200804'\n",
    "# api_key = '25b608ff66c249a888e104624200804'\n",
    "\n",
    "location_list = districts\n",
    "location_list.append('Delhi')\n",
    "print(location_list)\n",
    "hist_weather_data = retrieve_hist_data(api_key,\n",
    "                                location_list,\n",
    "                                start_date,\n",
    "                                end_date,\n",
    "                                frequency,\n",
    "                                location_label = False,\n",
    "                                export_csv = True,\n",
    "                                store_df = True)\n",
    "os.chdir(r\"C:\\Users\\Sarthak Vishnoi\\TSF-Challenge\\Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosed_date</th>\n",
       "      <th>detected_district</th>\n",
       "      <th>current_status</th>\n",
       "      <th>status_change_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04-03-2020</td>\n",
       "      <td>Agra</td>\n",
       "      <td>Hospitalized</td>\n",
       "      <td>04-03-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04-03-2020</td>\n",
       "      <td>Agra</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>15-03-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-03-2020</td>\n",
       "      <td>Agra</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>15-03-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-03-2020</td>\n",
       "      <td>Agra</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>15-03-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04-03-2020</td>\n",
       "      <td>Agra</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>15-03-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>08-04-2020</td>\n",
       "      <td>Vadodara</td>\n",
       "      <td>Hospitalized</td>\n",
       "      <td>08-04-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>08-04-2020</td>\n",
       "      <td>Vadodara</td>\n",
       "      <td>Hospitalized</td>\n",
       "      <td>08-04-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>08-04-2020</td>\n",
       "      <td>Vadodara</td>\n",
       "      <td>Hospitalized</td>\n",
       "      <td>08-04-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>08-04-2020</td>\n",
       "      <td>Vadodara</td>\n",
       "      <td>Hospitalized</td>\n",
       "      <td>08-04-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>08-04-2020</td>\n",
       "      <td>Vadodara</td>\n",
       "      <td>Hospitalized</td>\n",
       "      <td>08-04-2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2338 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosed_date detected_district current_status status_change_date\n",
       "0        04-03-2020              Agra   Hospitalized         04-03-2020\n",
       "1        04-03-2020              Agra      Recovered         15-03-2020\n",
       "2        04-03-2020              Agra      Recovered         15-03-2020\n",
       "3        04-03-2020              Agra      Recovered         15-03-2020\n",
       "4        04-03-2020              Agra      Recovered         15-03-2020\n",
       "...             ...               ...            ...                ...\n",
       "2333     08-04-2020          Vadodara   Hospitalized         08-04-2020\n",
       "2334     08-04-2020          Vadodara   Hospitalized         08-04-2020\n",
       "2335     08-04-2020          Vadodara   Hospitalized         08-04-2020\n",
       "2336     08-04-2020          Vadodara   Hospitalized         08-04-2020\n",
       "2337     08-04-2020          Vadodara   Hospitalized         08-04-2020\n",
       "\n",
       "[2338 rows x 4 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing the analysis for all the districts\n",
    "# Collecting the districts\n",
    "districtData = data1.drop(['id', 'nationality'], axis=1)\n",
    "delhiData = data1.drop(['id', 'nationality'], axis=1)\n",
    "\n",
    "for index,row in districtData.iterrows():\n",
    "    if(not(row['detected_district'] in districts)):\n",
    "        districtData.drop(index, inplace=True)\n",
    "districtData.reset_index(inplace = True, drop = True)\n",
    "districtData = districtData.drop(['government_id', 'age', 'gender', 'detected_city', 'detected_state', 'notes'], axis=1)\n",
    "districtData\n",
    "\n",
    "# For Delhi\n",
    "for index,row in delhiData.iterrows():\n",
    "    if((not(row['detected_district'] in delhi)) and (not(row['detected_state'] in delhiState))):\n",
    "        delhiData.drop(index, inplace=True)\n",
    "delhiData.reset_index(inplace = True, drop = True)\n",
    "delhiData = delhiData.drop(['government_id', 'age', 'gender', 'detected_city', 'detected_state', 'notes'], axis=1)\n",
    "delhiData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guntur\n",
      "Kurnool\n",
      "Ahmadabad\n",
      "Vadodara\n",
      "Bengaluru\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-232-04f0503e88f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mlockdown\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m#       For dist Cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdistrictData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'detected_district'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdistrict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mcheckDateObj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'diagnosed_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%d-%m-%Y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\envs\\Sarthak\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36miterrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    950\u001b[0m         \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    953\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\envs\\Sarthak\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\envs\\Sarthak\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5283\u001b[0m         \u001b[1;31m# the same attribute.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5285\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5286\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5287\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Making time series data for each district. Temperature and Humidity will be added to this, also, lockdown. \n",
    "# We don't need notes as it is individual level data\n",
    "# Status change date will help us with recovered and died cases.\n",
    "# districtCols1 = ['diagnosed_date', 'detected_district', 'current_status', 'status_change_date']\n",
    "dates = []\n",
    "districtCols = ['New Cases', 'Lockdown'] \n",
    "districtRHCols = ['Temp_0', 'Temp_1', 'Temp_2', 'Temp_3', 'Temp_4', 'Temp_5', 'Temp_6', 'Temp_7',\n",
    "       'Temp_8', 'Temp_9', 'Temp_10', 'Temp_11', 'Temp_12', 'Temp_13',\n",
    "       'Temp_14', 'RH_0', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6',\n",
    "       'RH_7', 'RH_8', 'RH_9', 'RH_10', 'RH_11', 'RH_12', 'RH_13', 'RH_14']\n",
    "\n",
    "lockdown_date_str = \"25-03-2020\"\n",
    "lockdown_date_obj = datetime.strptime(lockdown_date_str, '%d-%m-%Y').date()\n",
    "start_date_str = \"30-01-2020\"\n",
    "start_date_obj = datetime.strptime(start_date_str, '%d-%m-%Y').date()\n",
    "end_date_str = \"12-04-2020\"\n",
    "end_date_obj = datetime.strptime(end_date_str, '%d-%m-%Y').date()\n",
    "# Total 70 days\n",
    "days = 74\n",
    "for district in districts:\n",
    "    print(district)\n",
    "    distCases = np.zeros([days,2])\n",
    "    distRH = np.zeros([days,30])\n",
    "    index = 0\n",
    "    for dt in daterange(start_date_obj, end_date_obj):\n",
    "        currDate = dt.strftime(\"%d-%m-%Y\")\n",
    "        currDateObj = datetime.strptime(currDate, '%d-%m-%Y').date()\n",
    "#         Adding current date\n",
    "        dates.append(currDate)\n",
    "        newCases = 0\n",
    "        recovered = 0\n",
    "        died = 0\n",
    "        lockdown = 0\n",
    "        if(currDateObj >= lockdown_date_obj):\n",
    "            lockdown += 1\n",
    "#       For dist Cases\n",
    "        for _,row in districtData.iterrows():\n",
    "            if(row['detected_district'] == district):\n",
    "                checkDateObj = datetime.strptime(row['diagnosed_date'], '%d-%m-%Y').date()\n",
    "                if(currDateObj == checkDateObj):\n",
    "                    newCases += 1\n",
    "#                 if(isinstance(row['status_change_date'], str)):\n",
    "#                     statusDateObj = datetime.strptime(row['status_change_date'], '%d-%m-%Y').date()\n",
    "#                     if(currDateObj == statusDateObj):\n",
    "#                         if(row['current_status'] == 'Recovered'):\n",
    "#                             recovered += 1\n",
    "#                         elif(row['current_status'] == 'Deceased'):\n",
    "#                             died += 1\n",
    "        distCases[index,0] = newCases\n",
    "#         distCases[index,1] = recovered\n",
    "#         distCases[index,2] = died\n",
    "        distCases[index,1] = lockdown\n",
    "#       For RH and Temp\n",
    "        if((district in diffDist)):\n",
    "            nameDist = diffDist[district]\n",
    "        else:\n",
    "            nameDist = district\n",
    "        tempData = pd.read_csv('./Weather/' + nameDist + '.csv')\n",
    "        for index_,row_ in tempData.iterrows():\n",
    "            date_str2 = row_['date_time']\n",
    "            tempDateObj = datetime.strptime(date_str2, '%Y-%m-%d').date()\n",
    "            if(currDateObj == tempDateObj):\n",
    "                for i in range(15):\n",
    "                    distRH[index,i] = tempData['FeelsLikeC'][index_-i]\n",
    "                    distRH[index,i+15] = tempData['humidity'][index_-i]\n",
    "        index += 1\n",
    "        \n",
    "#       Saving this CSV file\n",
    "        datesDF = pd.DataFrame(data=dates, columns=['Date'])\n",
    "        distCasesDF = pd.DataFrame(data=distCases, columns=districtCols)\n",
    "        distRHDF = pd.DataFrame(data=distRH, columns=districtRHCols)\n",
    "        districtDF = pd.concat([datesDF, distCasesDF, distRHDF], axis=1, sort=False)\n",
    "        districtDF.to_csv('./Districts/' + nameDist + '.csv',index=False)\n",
    "    \n",
    "    \n",
    "# #     First start with making a dataframe for each district\n",
    "#     districtDF = pd.DataFrame(columns=districtCols1)\n",
    "#     for index,row in districtData.iterrows():\n",
    "#         if(row['detected_district'] == district):\n",
    "#             districtDF = districtDF.append(districtData.iloc[index,:], ignore_index=True)\n",
    "#     numRows = districtDF.shape[0]\n",
    "# #     Getting the new number of cases and making an np array for other details    \n",
    "#     districtTimeSeriesData = np.zeros([numRows, 4])\n",
    "#     districtRHData = np.zeros([numRows, 30])\n",
    "# #     print(districtDF)\n",
    "# #     Assume data is in ascending order of dates\n",
    "#     for counter1 in range(numRows):\n",
    "#         date_obj1 = datetime.strptime(str(districtDF['diagnosed_date'][counter1]), '%d-%m-%Y').date()\n",
    "#         count = 0\n",
    "#         for counter2 in range(numRows):\n",
    "#             date_obj2 = datetime.strptime(districtDF['diagnosed_date'][counter2], '%d-%m-%Y').date()\n",
    "#             if(date_obj1 == date_obj2):\n",
    "#                 count += 1\n",
    "#             elif(date_obj1 < date_obj2):\n",
    "#                 break\n",
    "#         districtTimeSeriesData[counter1,0] = count\n",
    "# #     for recovered and deceased\n",
    "#     for counter1 in range(numRows):\n",
    "#         date_obj1 = datetime.strptime(districtDF['diagnosed_date'][counter1], '%d-%m-%Y').date()\n",
    "# #         Lockdown\n",
    "#         if(date_obj1 >= lockdown_date_obj):\n",
    "#             districtTimeSeriesData[counter1, 3] = 1\n",
    "#         recovered = 0\n",
    "#         died = 0\n",
    "#         for counter2 in range(numRows):\n",
    "#             if(isinstance(districtDF['status_change_date'][counter2], float)):\n",
    "#                 continue\n",
    "#             date_obj2 = datetime.strptime(districtDF['status_change_date'][counter2], '%d-%m-%Y').date()\n",
    "#             if(date_obj1 == date_obj2):\n",
    "#                 if(districtDF['current_status'][counter2] == 'Recovered'):\n",
    "#                     recovered += 1\n",
    "#                 elif(districtDF['current_status'][counter2] == 'Deceased'):\n",
    "#                     died += 1\n",
    "#         districtTimeSeriesData[counter1, 1] = recovered\n",
    "#         districtTimeSeriesData[counter1, 2] = died\n",
    "# #     RH Data\n",
    "    \n",
    "#     if((district in diffDist)):\n",
    "#         nameDist = diffDist[district]\n",
    "#     else:\n",
    "#         nameDist = district\n",
    "    \n",
    "#     tempData = pd.read_csv('./Weather/' + nameDist + '.csv')\n",
    "#     print(numRows)\n",
    "#     for index in range(numRows):\n",
    "#         date_obj1 = datetime.strptime(districtDF['diagnosed_date'][index], '%d-%m-%Y').date()\n",
    "#         for index_,row_ in tempData.iterrows():\n",
    "#             date_str2 = row_['date_time']\n",
    "#             date_object2 = datetime.strptime(date_str2, '%Y-%m-%d').date()\n",
    "#             if(date_obj1 == date_object2):\n",
    "#                 for i in range(15):\n",
    "#                     districtRHData[index,i] = tempData['FeelsLikeC'][index_-i]\n",
    "#                     districtRHData[index,i+15] = tempData['humidity'][index_-i]\n",
    "# #     Making a big dataframe\n",
    "#     districtRHDF = pd.DataFrame(data=districtRHData, columns=districtRH)\n",
    "#     districtTimeSeriesDF = pd.DataFrame(data=districtTimeSeriesData, columns=districtCols2)\n",
    "#     district_DF = pd.concat([districtDF, districtTimeSeriesDF, districtRHDF], axis=1, sort=False)\n",
    "#     finalCSVcols = district_DF.columns\n",
    "    \n",
    "# #     Make the data like a time series and not like individual details\n",
    "#     for dt in daterange(start_date_obj, end_date_obj):\n",
    "#         for index,row in district_DF.iterrows():\n",
    "# #     district_DF.to_csv('./Districts/' + nameDist + '.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing this for Delhi, not a duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making time series data for each district. Temperature and Humidity will be added to this, also, lockdown. \n",
    "# We don't need notes as it is individual level data\n",
    "# Status change date will help us with recovered and died cases.\n",
    "# districtCols1 = ['diagnosed_date', 'detected_district', 'current_status', 'status_change_date']\n",
    "dates = []\n",
    "districtCols = ['New Cases', 'Lockdown'] \n",
    "districtRHCols = ['Temp_0', 'Temp_1', 'Temp_2', 'Temp_3', 'Temp_4', 'Temp_5', 'Temp_6', 'Temp_7',\n",
    "       'Temp_8', 'Temp_9', 'Temp_10', 'Temp_11', 'Temp_12', 'Temp_13',\n",
    "       'Temp_14', 'RH_0', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6',\n",
    "       'RH_7', 'RH_8', 'RH_9', 'RH_10', 'RH_11', 'RH_12', 'RH_13', 'RH_14']\n",
    "\n",
    "lockdown_date_str = \"25-03-2020\"\n",
    "lockdown_date_obj = datetime.strptime(lockdown_date_str, '%d-%m-%Y').date()\n",
    "start_date_str = \"30-01-2020\"\n",
    "start_date_obj = datetime.strptime(start_date_str, '%d-%m-%Y').date()\n",
    "end_date_str = \"08-04-2020\"\n",
    "end_date_obj = datetime.strptime(end_date_str, '%d-%m-%Y').date()\n",
    "# Total 70 days\n",
    "days = 70\n",
    "distCases = np.zeros([days,2])\n",
    "distRH = np.zeros([days,30])\n",
    "index = 0\n",
    "   \n",
    "for dt in daterange(start_date_obj, end_date_obj):\n",
    "    currDate = dt.strftime(\"%d-%m-%Y\")\n",
    "    currDateObj = datetime.strptime(currDate, '%d-%m-%Y').date()\n",
    "#   Adding current date\n",
    "    dates.append(currDate)\n",
    "    newCases = 0\n",
    "    recovered = 0\n",
    "    died = 0\n",
    "    lockdown = 0\n",
    "    if(currDateObj >= lockdown_date_obj):\n",
    "        lockdown += 1\n",
    "#   For dist Cases\n",
    "    for _,row in districtData.iterrows():\n",
    "        checkDateObj = datetime.strptime(row['diagnosed_date'], '%d-%m-%Y').date()\n",
    "        if(currDateObj == checkDateObj):\n",
    "            newCases += 1\n",
    "#         if(isinstance(row['status_change_date'], str)):\n",
    "#             statusDateObj = datetime.strptime(row['status_change_date'], '%d-%m-%Y').date()\n",
    "#             if(currDateObj == statusDateObj):\n",
    "#                 if(row['current_status'] == 'Recovered'):\n",
    "#                     recovered += 1\n",
    "#                 elif(row['current_status'] == 'Deceased'):\n",
    "#                     died += 1\n",
    "    distCases[index,0] = newCases\n",
    "#     distCases[index,1] = recovered\n",
    "#     distCases[index,2] = died\n",
    "    distCases[index,1] = lockdown\n",
    "#   For RH and Temp\n",
    "    nameDist = 'Delhi'\n",
    "    tempData = pd.read_csv('./Weather/' + nameDist + '.csv')\n",
    "    for index_,row_ in tempData.iterrows():\n",
    "        date_str2 = row_['date_time']\n",
    "        tempDateObj = datetime.strptime(date_str2, '%Y-%m-%d').date()\n",
    "        if(currDateObj == tempDateObj):\n",
    "            for i in range(15):\n",
    "                distRH[index,i] = tempData['FeelsLikeC'][index_-i]\n",
    "                distRH[index,i+15] = tempData['humidity'][index_-i]\n",
    "    index += 1\n",
    "\n",
    "#   Saving this CSV file\n",
    "    datesDF = pd.DataFrame(data=dates, columns=['Date'])\n",
    "    distCasesDF = pd.DataFrame(data=distCases, columns=districtCols)\n",
    "    distRHDF = pd.DataFrame(data=distRH, columns=districtRHCols)\n",
    "    districtDF = pd.concat([datesDF, distCasesDF, distRHDF], axis=1, sort=False)\n",
    "    districtDF.to_csv('./Districts/' + nameDist + '.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
