{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download any package here\n",
    "# # Install a pip package in the current Jupyter kernel\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "from datetime import timedelta, date\n",
    "from wwo_hist import retrieve_hist_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13664 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>government_id</th>\n",
       "      <th>diagnosed_date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>detected_city</th>\n",
       "      <th>detected_district</th>\n",
       "      <th>detected_state</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KL-TS-P1</td>\n",
       "      <td>30/01/2020</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>Thrissur</td>\n",
       "      <td>Thrissur</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Travelled from Wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KL-AL-P1</td>\n",
       "      <td>02/02/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Travelled from Wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KL-KS-P1</td>\n",
       "      <td>03/02/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kasaragod</td>\n",
       "      <td>Kasaragod</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Travelled from Wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL-P1</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>East Delhi (Mayur Vihar)</td>\n",
       "      <td>East Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Travelled from Austria, Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TS-P1</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Travelled from Dubai to Bangalore on 20th Feb,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  government_id diagnosed_date  age gender             detected_city  \\\n",
       "0      KL-TS-P1     30/01/2020   20      F                  Thrissur   \n",
       "1      KL-AL-P1     02/02/2020  NaN    NaN                 Alappuzha   \n",
       "2      KL-KS-P1     03/02/2020  NaN    NaN                 Kasaragod   \n",
       "3         DL-P1     02/03/2020   45      M  East Delhi (Mayur Vihar)   \n",
       "4         TS-P1     02/03/2020   24      M                 Hyderabad   \n",
       "\n",
       "  detected_district detected_state  \\\n",
       "0          Thrissur         Kerala   \n",
       "1         Alappuzha         Kerala   \n",
       "2         Kasaragod         Kerala   \n",
       "3        East Delhi          Delhi   \n",
       "4         Hyderabad      Telangana   \n",
       "\n",
       "                                               notes  \n",
       "0                               Travelled from Wuhan  \n",
       "1                               Travelled from Wuhan  \n",
       "2                               Travelled from Wuhan  \n",
       "3                      Travelled from Austria, Italy  \n",
       "4  Travelled from Dubai to Bangalore on 20th Feb,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the individual data\n",
    "data1 = pd.read_csv('IndividualDetails.csv')\n",
    "# print(data.shape)\n",
    "# data.head()\n",
    "# Deleting id, nationality, status_change_date\n",
    "data = data1.drop(['id', 'nationality', 'status_change_date'], axis=1)\n",
    "# data.head()\n",
    "rows = data.shape[0]\n",
    "columns = data.shape[1]\n",
    "print(rows, columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alappuzha'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['detected_city'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Making a list of foreign cities and countries where the person might have contracted the virus\n",
    "# foreignList = ['Wuhan', 'Italy', 'Austria', 'Dubai', 'Iran', 'Malaysia', 'Doha']\n",
    "# For ARIMA we can also make age brackets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>government_id</th>\n",
       "      <th>diagnosed_date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>detected_city</th>\n",
       "      <th>detected_district</th>\n",
       "      <th>detected_state</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KL-TS-P1</td>\n",
       "      <td>30/01/2020</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>Thrissur</td>\n",
       "      <td>Thrissur</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Travelled from Wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KL-AL-P1</td>\n",
       "      <td>02/02/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Travelled from Wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KL-KS-P1</td>\n",
       "      <td>03/02/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kasaragod</td>\n",
       "      <td>Kasaragod</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Travelled from Wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL-P1</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>East Delhi (Mayur Vihar)</td>\n",
       "      <td>East Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Travelled from Austria, Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TS-P1</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Travelled from Dubai to Bangalore on 20th Feb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>04/03/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Agra</td>\n",
       "      <td>Agra</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Family members of P4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  government_id diagnosed_date  age gender             detected_city  \\\n",
       "0      KL-TS-P1     30/01/2020   20      F                  Thrissur   \n",
       "1      KL-AL-P1     02/02/2020  NaN    NaN                 Alappuzha   \n",
       "2      KL-KS-P1     03/02/2020  NaN    NaN                 Kasaragod   \n",
       "3         DL-P1     02/03/2020   45      M  East Delhi (Mayur Vihar)   \n",
       "4         TS-P1     02/03/2020   24      M                 Hyderabad   \n",
       "5           NaN     04/03/2020  NaN      M                      Agra   \n",
       "\n",
       "  detected_district detected_state  \\\n",
       "0          Thrissur         Kerala   \n",
       "1         Alappuzha         Kerala   \n",
       "2         Kasaragod         Kerala   \n",
       "3        East Delhi          Delhi   \n",
       "4         Hyderabad      Telangana   \n",
       "5              Agra  Uttar Pradesh   \n",
       "\n",
       "                                               notes  \n",
       "0                               Travelled from Wuhan  \n",
       "1                               Travelled from Wuhan  \n",
       "2                               Travelled from Wuhan  \n",
       "3                      Travelled from Austria, Italy  \n",
       "4  Travelled from Dubai to Bangalore on 20th Feb,...  \n",
       "5                               Family members of P4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping rows without districts\n",
    "for index,row in data.iterrows():\n",
    "    if(not(row['detected_district'] == row['detected_district'])):\n",
    "        data.drop(index, inplace=True)\n",
    "    elif((row['detected_district'] == 'Italians*') or (row['detected_district'] == 'Evacuees') or (row['detected_district'] == 'Gujarat*')):\n",
    "        data.drop(index, inplace=True)\n",
    "data.reset_index(inplace = True, drop = True)\n",
    "data.head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a dictionary of districts whose csv files are named something else\n",
    "diffDist = {}\n",
    "diffDist['Ahmadnagar'] = 'Ahmednagar'\n",
    "diffDist['Ahmadabad'] = 'Ahmedabad'\n",
    "diffDist['Ballari'] = 'Bellary'\n",
    "diffDist['Bagalkote'] = 'Bagalkot'\n",
    "diffDist['Bhivani'] = 'Bhiwani'\n",
    "diffDist['Bara Banki'] = 'Bara+Banki'\n",
    "diffDist['Bengaluru Rural'] = 'Bengaluru+Rural'\n",
    "diffDist['Bhadradri Kothagudem'] = 'Bhadradri+Kothagudem'\n",
    "diffDist['Charki Dadri'] = 'Charki+Dadri'\n",
    "diffDist['Chikkaballapura'] = 'Chikkaballapur'\n",
    "diffDist['Chota Udaipur'] = 'Chota+Udaipur'\n",
    "diffDist['Dakshina Kannada'] = 'Dakshina+Kannada'\n",
    "diffDist['East Delhi'] = 'East+Delhi'\n",
    "diffDist['East Godavari'] = 'East+Godavari'\n",
    "diffDist['Fatehgarh Sahib'] = 'Fatehgarh+Sahib'\n",
    "diffDist['Gautam Buddha Nagar'] = 'Gautam+Buddh+Nagar'\n",
    "diffDist['Gir Somnath'] = 'Gir'\n",
    "diffDist['Goalaghat'] = 'Golaghat'\n",
    "diffDist['Gondiya'] = 'Gondia'\n",
    "diffDist['Gurugram'] = 'Gurgaon'\n",
    "diffDist['Hatras'] = 'Hathras'\n",
    "diffDist['Imphal West'] = 'Imphal'\n",
    "diffDist['Jagitial'] = 'Jagtial'\n",
    "diffDist['Jogulamba Gadwal'] = 'Gadwal'\n",
    "diffDist['Kachchh'] = 'Kutch'\n",
    "diffDist['Kamrup Metropolitan'] = 'Kamrup'\n",
    "diffDist['Kancheepuram'] = 'Kanchipuram'\n",
    "diffDist['Kanniyakumari'] = 'Kanyakumari'\n",
    "diffDist['Kanpur Nagar'] = 'Kanpur'\n",
    "diffDist['Mahesana'] = 'Mehsana'\n",
    "diffDist['Mahabubnagar'] = 'Mahbubnagar'\n",
    "diffDist['Mahrajganj'] = 'Maharajganj'\n",
    "diffDist['Medchal Malkajgiri'] = 'Medchal'\n",
    "diffDist['Medinipur East'] = 'Midnapore'\n",
    "diffDist['Mumbai Suburban'] = 'Mumbai+Suburban'\n",
    "diffDist['New Delhi'] = 'New+Delhi'\n",
    "diffDist['North 24 Parganas'] = 'Barasat'\n",
    "diffDist['North and Middle Andaman'] = 'Mayabunder'\n",
    "diffDist['North Delhi'] = 'North+Delhi'\n",
    "diffDist['North East Delhi'] = 'North+East+Delhi'\n",
    "diffDist['North Goa'] = 'North+Goa'\n",
    "diffDist['North West Delhi'] = 'North+West+Delhi'\n",
    "diffDist['Panch Mahals'] = 'Godhra'\n",
    "diffDist['Pauri Garhwal'] = 'Pauri'\n",
    "diffDist['Rae Bareli'] = 'Rae+Bareli'\n",
    "diffDist['Ranga Reddy'] = 'Shamshabad'\n",
    "diffDist['S.A.S. Nagar'] = 'Mohali'\n",
    "diffDist['S.P.S. Nellore'] = 'Nellore'\n",
    "diffDist['Sabar Kantha'] = 'Himatnagar'\n",
    "diffDist['Shahid Bhagat Singh Nagar'] = 'Nawanshahr'\n",
    "diffDist['South 24 Parganas'] = 'Alipore'\n",
    "diffDist['South Andaman'] = 'Port+Blair'\n",
    "diffDist['South Delhi'] = 'South+Delhi'\n",
    "diffDist['South West Delhi'] = 'South+West+Delhi'\n",
    "diffDist['South Salmara Mancachar'] = 'Hatsingimari'\n",
    "diffDist['The Nilgiris'] = 'Udhagamandalam'\n",
    "diffDist['Thoothukkudi'] = 'Thoothukudi'\n",
    "diffDist['Udham Singh Nagar'] = 'Rudrapur'\n",
    "diffDist['Uttara Kannada'] = 'Bhatkal'\n",
    "diffDist['Warangal Urban'] = 'Warangal'\n",
    "diffDist['West Delhi'] = 'West+Delhi'\n",
    "diffDist['West Godavari'] = 'West+Godavari'\n",
    "diffDist['Y.S.R.'] = 'Kadapa'\n",
    "len(diffDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating an empty data fram which would contain details for temperature and RH\n",
    "# rows = data.shape[0]\n",
    "# tempRH = np.zeros((rows, 30))\n",
    "# for index,row in data.iterrows():\n",
    "#     print(index)\n",
    "#     if((row['detected_district'] in diffDist)):\n",
    "#         tempDist = diffDist[row['detected_district']]\n",
    "#     else:\n",
    "#         tempDist = row['detected_district']\n",
    "#     print(tempDist)\n",
    "#     tempData = pd.read_csv('./Weather/' + tempDist + '.csv')\n",
    "#     date_str1 = row['diagnosed_date']\n",
    "#     date_object1 = datetime.strptime(date_str1, '%d-%m-%Y').date()\n",
    "#     for index_,row_ in tempData.iterrows():\n",
    "#         date_str2 = row_['date_time']\n",
    "#         date_object2 = datetime.strptime(date_str2, '%Y-%m-%d').date()\n",
    "#         if(date_object1 == date_object2):\n",
    "# #             print(\"Hi\")\n",
    "#             for i in range(15):\n",
    "#                 tempRH[index,i] = tempData['FeelsLikeC'][index_-i]\n",
    "#                 tempRH[index,i+15] = tempData['humidity'][index_-i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatinating two data frames\n",
    "# cols = ['Temp_0', 'Temp_1', 'Temp_2', 'Temp_3', 'Temp_4', 'Temp_5', 'Temp_6', 'Temp_7', 'Temp_8', 'Temp_9', 'Temp_10', 'Temp_11', 'Temp_12', 'Temp_13', 'Temp_14', 'RH_0', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7', 'RH_8', 'RH_9', 'RH_10', 'RH_11', 'RH_12', 'RH_13', 'RH_14']\n",
    "# tempRHdf = pd.DataFrame(data=tempRH, columns=cols)\n",
    "# result = pd.concat([data, tempRHdf], axis=1, sort=False)\n",
    "# result.head()\n",
    "# # result.to_csv('individualDetailsModified.csv',index=False)\n",
    "# print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # places = ['Wuhan', 'Austria', 'Italy', 'Germany', 'Dubai', 'Mecca', 'Oman', 'USA', 'US', 'UK', 'Thailand', 'Iran', 'Qatar', 'Middle East', 'Singapore', 'Philippines', 'Mecca', 'Saudi Arabia', 'Japan', 'Spain', ]\n",
    "# china = ['China', 'Wuhan']\n",
    "# usa = ['USA', 'US', 'New York', 'San Francisco', 'California']\n",
    "# middleEast = ['Dubai', 'Abu Dhabi', 'UAE', 'Mecca', 'Saudi Arabia', 'Middle East', 'Doha', 'Qatar', 'Kuwait', 'Bahrain', 'Iran', 'Oman', 'Saudi', 'Finland']\n",
    "# europeExItaly = ['UK', 'France', 'Austria', 'Germany', 'London', 'Spain', 'Paris', 'Russia']\n",
    "# italy = ['Italy', 'Rome']\n",
    "# southEastAsia = ['Singapore', 'Thailand', 'Philippines', 'Malaysia', 'Bangkok', 'Phuket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extracting information from notes\n",
    "# print(rows)\n",
    "# result['notes'] = result['notes'].str.replace(',',' ')\n",
    "# result['notes'] = result['notes'].str.replace('-',' ')\n",
    "# result['notes'] = result['notes'].str.replace(';',' ')\n",
    "# result['notes'] = result['notes'].str.replace('.',' ')\n",
    "# # Making a numpy barray for storing these binary variables, can add details for jamat when they come\n",
    "# places = np.zeros((rows,6))\n",
    "# for i in range (rows):\n",
    "#     if(not(isinstance(result['notes'][i],str))):\n",
    "#         continue\n",
    "#     words = (result['notes'][i]).split()\n",
    "#     for place in china:\n",
    "#         if place in words:\n",
    "#             places[i,0] = 1\n",
    "#     for place in usa:\n",
    "#         if place in words:\n",
    "#             places[i,1] = 1\n",
    "#     for place in middleEast:\n",
    "#         if place in words:\n",
    "#             places[i,2] = 1\n",
    "#     for place in europeExItaly:\n",
    "#         if place in words:\n",
    "#             places[i,3] = 1\n",
    "#     for place in italy:\n",
    "#         if place in words:\n",
    "#             places[i,4] = 1\n",
    "#     for place in southEastAsia:\n",
    "#         if place in words:\n",
    "#             places[i,5] = 1\n",
    "# colPlaces = ['China', 'USA', 'Middle_East', 'Europe_Ex_Italy', 'Italy', 'South_East_Asia']\n",
    "# placesDF = pd.DataFrame(data=places, columns=colPlaces)      \n",
    "# resultWithPlaces = pd.concat([result, placesDF], axis=1, sort=False)\n",
    "# resultWithPlaces = resultWithPlaces.drop(['notes'], axis=1)\n",
    "# print(resultWithPlaces.shape)\n",
    "# print(resultWithPlaces.head())\n",
    "# resultWithPlaces.to_csv('individualDetailsModified.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Status</th>\n",
       "      <th>TT</th>\n",
       "      <th>AN</th>\n",
       "      <th>AP</th>\n",
       "      <th>AR</th>\n",
       "      <th>AS</th>\n",
       "      <th>BR</th>\n",
       "      <th>CH</th>\n",
       "      <th>CT</th>\n",
       "      <th>...</th>\n",
       "      <th>PY</th>\n",
       "      <th>PB</th>\n",
       "      <th>RJ</th>\n",
       "      <th>SK</th>\n",
       "      <th>TN</th>\n",
       "      <th>TG</th>\n",
       "      <th>TR</th>\n",
       "      <th>UP</th>\n",
       "      <th>UT</th>\n",
       "      <th>WB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14-Mar-20</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14-Mar-20</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14-Mar-20</td>\n",
       "      <td>Deceased</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-Mar-20</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-Mar-20</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>14-Apr-20</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>14-Apr-20</td>\n",
       "      <td>Deceased</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>15-Apr-20</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>15-Apr-20</td>\n",
       "      <td>Recovered</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>15-Apr-20</td>\n",
       "      <td>Deceased</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Status   TT  AN    AP  AR  AS  BR  CH  CT  ...  PY  PB  RJ  \\\n",
       "0   14-Mar-20  Confirmed   79   0   1.0   0   0   0   0   0  ...   0   1   3   \n",
       "1   14-Mar-20  Recovered    9   0   0.0   0   0   0   0   0  ...   0   0   1   \n",
       "2   14-Mar-20   Deceased    2   0   0.0   0   0   0   0   0  ...   0   0   0   \n",
       "3   15-Mar-20  Confirmed   28   0   0.0   0   0   0   0   0  ...   0   0   1   \n",
       "4   15-Mar-20  Recovered    4   0   0.0   0   0   0   0   0  ...   0   0   2   \n",
       "..        ...        ...  ...  ..   ...  ..  ..  ..  ..  ..  ...  ..  ..  ..   \n",
       "94  14-Apr-20  Recovered  167   0   4.0   0   0   1   0   3  ...   0   2  26   \n",
       "95  14-Apr-20   Deceased   37   0   4.0   0   0   0   0   0  ...   0   1   0   \n",
       "96  15-Apr-20  Confirmed  882   0  41.0   0   0   6   0   0  ...   0   2  71   \n",
       "97  15-Apr-20  Recovered  144   0   4.0   1   2   0   2   4  ...   0   0   0   \n",
       "98  15-Apr-20   Deceased   27   0   3.0   0   0   0   0   0  ...   0   0   0   \n",
       "\n",
       "    SK  TN  TG  TR  UP  UT  WB  \n",
       "0    0   1   1   0  12   0   0  \n",
       "1    0   0   0   0   4   0   0  \n",
       "2    0   0   0   0   0   0   0  \n",
       "3    0   0   2   0   1   0   0  \n",
       "4    0   0   1   0   0   0   0  \n",
       "..  ..  ..  ..  ..  ..  ..  ..  \n",
       "94   0  23   7   0   1   2   7  \n",
       "95   0   1   1   0   3   0   0  \n",
       "96   0  38   6   0  75   0  23  \n",
       "97   0  37   8   1   7   0   1  \n",
       "98   0   2   0   0   3   0   0  \n",
       "\n",
       "[99 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File with timeseries data state wise\n",
    "ts = pd.read_csv('StateWiseDaily.csv')\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resCols = resultWithPlaces.columns\n",
    "# print(resCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "# Creating different CSV files for individual analysis with temperature and Humidity\n",
    "# Using individual details, can be used for pooled data analysis in future, see it again\n",
    "states = ['Andaman and Nicobar Islands', 'Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar', 'Chandigarh', 'Chhattisgarh',\n",
    "          'Dadra and Nagar Haveli', 'Delhi', 'Goa', 'Gujarat', 'Haryana', 'Himachal Pradesh', 'Jammu and Kashmir', 'Jharkhand',\n",
    "          'Karnataka', 'Kerala', 'Ladakh', 'Madhya Pradesh', 'Maharashtra', 'Manipur', 'Mizoram', 'Nagaland', 'Odisha', \n",
    "          'Puducherry', 'Punjab', 'Rajasthan', 'Sikkim', 'Tamil Nadu', 'Telangana', 'Tripura', 'Uttar Pradesh',\n",
    "          'Uttarakhand', 'West Bengal']\n",
    "\n",
    "stateCodes = ['AN', 'AP', 'AR', 'AS', 'BR', 'CH', 'CT', \n",
    "              'DN', 'DL', 'GA', 'GJ', 'HR', 'HP', 'JK', 'JH', \n",
    "              'KA', 'KL', 'LA', 'MP', 'MH', 'MN', 'MZ', 'NL', 'OR', \n",
    "              'PY', 'PB', 'RJ', 'SK', 'TN', 'TG', 'TR', \n",
    "              'UP', 'UT', 'WB']\n",
    "print(len(states))\n",
    "print(len(stateCodes))\n",
    "# for state in states:\n",
    "#     indexState = states.index(state)\n",
    "#     stateCode = stateCodes[indexState]\n",
    "#     stateDF = pd.DataFrame(columns=resCols)\n",
    "#     for index,row in resultWithPlaces.iterrows():\n",
    "#         if(row['detected_state'] == state):\n",
    "#             stateDF = stateDF.append(resultWithPlaces.iloc[index,:], ignore_index=True)\n",
    "# #             Can use notes for foreign return\n",
    "#     stateDF = stateDF.drop(['government_id', 'age', 'gender', 'detected_city', 'detected_district','current_status'], axis=1)\n",
    "#     numRows = stateDF.shape[0]\n",
    "# #     print(stateDF.head())\n",
    "# #     New Cases, recovered, Died\n",
    "#     statusState = np.zeros((numRows, 4))\n",
    "#     # Fourth one is for lockdown\n",
    "#     lockdown_date_str = \"25-03-2020\"\n",
    "#     lockdown_date_obj = datetime.strptime(lockdown_date_str, '%d-%m-%Y').date() \n",
    "#     for index,row in stateDF.iterrows():\n",
    "#         date_str1 = row['diagnosed_date']\n",
    "#         date_object1 = datetime.strptime(date_str1, '%d-%m-%Y').date()\n",
    "#         for index_,row_ in ts.iterrows():\n",
    "#             date_str2 = row_['Date']\n",
    "#             date_object2 = datetime.strptime(date_str2, '%d-%b-%y').date()\n",
    "#             if(date_object1 == date_object2):\n",
    "#                 statusState[index,0] = ts.loc[index_,stateCode]\n",
    "#                 statusState[index,1] = ts.loc[index_+1,stateCode]\n",
    "#                 statusState[index,2] = ts.loc[index_+2,stateCode]\n",
    "#                 if(date_object1 >= lockdown_date_obj):\n",
    "#                     statusState[index,3] = 1\n",
    "#                 break\n",
    "                \n",
    "# #     Adding this numpy array to stateDF\n",
    "#     cols = ['newCases', 'Recovered', 'Deceased', 'Lockdown']\n",
    "#     statusStateDF = pd.DataFrame(data=statusState, columns=cols)\n",
    "#     stateDF = pd.concat([stateDF, statusStateDF], axis=1, sort=False)\n",
    "# #     print(stateDF.shape)\n",
    "#     stateDF.to_csv('./TimeSeries_with_Temp/' + state + '.csv',index=False)\n",
    "# #     print(\"The state \" + state + \" has \" + str(stateDF.shape[0]) + \" number of COVID-19 cases till 8/4/20.\")\n",
    "#     print(state + \" -> \" + str(stateDF.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series data without any explanatory variables, state-wise and total\n",
    "# Data from COVID-19 google drive\n",
    "newRows = int(ts.shape[0]/3)\n",
    "stateDFTScolumns=['NewCases', 'Recovered', 'Deaths', 'Lockdown']    \n",
    "lockdown_date_str = \"25-03-2020\"\n",
    "lockdown_date_obj = datetime.strptime(lockdown_date_str, '%d-%m-%Y').date()\n",
    "for stateCode in stateCodes:\n",
    "    statusStateTS = np.zeros([newRows,4])\n",
    "    dates = []\n",
    "    indexState = stateCodes.index(stateCode)\n",
    "    state = states[indexState]\n",
    "    for index in range(newRows):\n",
    "        dates.append(ts['Date'][3*index])\n",
    "        statusStateTS[index,0] = ts.loc[3*index,stateCode]\n",
    "        statusStateTS[index,1] = ts.loc[3*index+1,stateCode]\n",
    "        statusStateTS[index,2] = ts.loc[3*index+2,stateCode]\n",
    "        date_obj = datetime.strptime(ts['Date'][3*index], '%d-%b-%y').date()\n",
    "        if(date_obj >= lockdown_date_obj):\n",
    "            statusStateTS[index,3] = 1\n",
    "        \n",
    "    datesDF = pd.DataFrame(data=dates, columns=['Date'])    \n",
    "    stateStatusDFTS_temp = pd.DataFrame(data=statusStateTS, columns=stateDFTScolumns)\n",
    "    stateStatusDFTS = pd.concat([datesDF, stateStatusDFTS_temp], axis=1, sort=False)\n",
    "    stateStatusDFTS.to_csv('./TimeSeries/' + state + '.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will need to add time series data for before 15th March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Daily Confirmed</th>\n",
       "      <th>Total Confirmed</th>\n",
       "      <th>Daily Recovered</th>\n",
       "      <th>Total Recovered</th>\n",
       "      <th>Daily Deceased</th>\n",
       "      <th>Total Decease</th>\n",
       "      <th>Lockdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30-Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31-Jan</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-Feb</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02-Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date  Daily Confirmed  Total Confirmed  Daily Recovered  Total Recovered  \\\n",
       "0  30-Jan                1                1                0                0   \n",
       "1  31-Jan                0                1                0                0   \n",
       "2  01-Feb                0                1                0                0   \n",
       "3  02-Feb                1                2                0                0   \n",
       "4  03-Feb                1                3                0                0   \n",
       "\n",
       "   Daily Deceased  Total Decease  Lockdown  \n",
       "0               0              0         0  \n",
       "1               0              0         0  \n",
       "2               0              0         0  \n",
       "3               0              0         0  \n",
       "4               0              0         0  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# India Time series (with lockdown)\n",
    "# Data from COVID-19 India, add lockdown variable in it\n",
    "indiaTS = pd.read_csv('India_Time_Series.csv')\n",
    "indiaTS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guntur: 82\n",
      "Kurnool: 84\n",
      "Ahmadabad: 282\n",
      "Vadodara: 101\n",
      "Bengaluru: 76\n",
      "Kannur: 72\n",
      "Kasaragod: 166\n",
      "Bhopal: 134\n",
      "Indore: 311\n",
      "Mumbai: 1259\n",
      "Pune: 261\n",
      "Thane: 145\n",
      "Jaipur: 341\n",
      "Chennai: 200\n",
      "Coimbatore: 119\n",
      "Erode: 64\n",
      "Tiruppur: 61\n",
      "Hyderabad: 197\n",
      "Agra: 104\n",
      "4059\n"
     ]
    }
   ],
   "source": [
    "# Making Time Series data for districts with more than 100 cases, starting from 15th March\n",
    "\n",
    "# Finding districts with more than 100 cases so far, we'll add Delhi afterwards\n",
    "limit = 60 #Change here for changing the limit of 100\n",
    "os.chdir(r\"C:\\Users\\Sarthak Vishnoi\\TSF-Challenge\\Data\")\n",
    "districtData = pd.read_csv('DistrictWise.csv')\n",
    "districts = []\n",
    "delhi = ['Faridabad', 'Gautam Buddha Nagar', 'Ghaziabad', 'Gurugram']\n",
    "delhiState = ['Delhi']\n",
    "total = 0\n",
    "for index,row in districtData.iterrows():\n",
    "    if(row['Confirmed'] >= limit):\n",
    "        if(not(row['District'] in delhi)):\n",
    "            districts.append(row['District'])\n",
    "            print(row['District'] + \": \" + str(row['Confirmed']))\n",
    "            total += row['Confirmed']\n",
    "print(total)\n",
    "# print(districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Guntur', 'Kurnool', 'Ahmadabad', 'Vadodara', 'Bengaluru', 'Kannur', 'Kasaragod', 'Bhopal', 'Indore', 'Mumbai', 'Pune', 'Thane', 'Jaipur', 'Chennai', 'Coimbatore', 'Erode', 'Tiruppur', 'Hyderabad', 'Agra', 'Delhi', 'Delhi']\n",
      "\n",
      "\n",
      "Retrieving weather data for Guntur\n",
      "\n",
      "\n",
      "Currently retrieving data for Guntur: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.600035\n",
      "Currently retrieving data for Guntur: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.168530\n",
      "Currently retrieving data for Guntur: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.470697\n",
      "Currently retrieving data for Guntur: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.426728\n",
      "\n",
      "\n",
      "export Guntur completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Kurnool\n",
      "\n",
      "\n",
      "Currently retrieving data for Kurnool: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.385864\n",
      "Currently retrieving data for Kurnool: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.702452\n",
      "Currently retrieving data for Kurnool: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.150005\n",
      "Currently retrieving data for Kurnool: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.981476\n",
      "\n",
      "\n",
      "export Kurnool completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Ahmadabad\n",
      "\n",
      "\n",
      "Currently retrieving data for Ahmadabad: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.241658\n",
      "Currently retrieving data for Ahmadabad: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.634445\n",
      "Currently retrieving data for Ahmadabad: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.926203\n",
      "Currently retrieving data for Ahmadabad: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.772857\n",
      "\n",
      "\n",
      "export Ahmadabad completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Vadodara\n",
      "\n",
      "\n",
      "Currently retrieving data for Vadodara: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.422403\n",
      "Currently retrieving data for Vadodara: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.667564\n",
      "Currently retrieving data for Vadodara: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.929716\n",
      "Currently retrieving data for Vadodara: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.761065\n",
      "\n",
      "\n",
      "export Vadodara completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Bengaluru\n",
      "\n",
      "\n",
      "Currently retrieving data for Bengaluru: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.422332\n",
      "Currently retrieving data for Bengaluru: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.747996\n",
      "Currently retrieving data for Bengaluru: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.219697\n",
      "Currently retrieving data for Bengaluru: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.233140\n",
      "\n",
      "\n",
      "export Bengaluru completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Kannur\n",
      "\n",
      "\n",
      "Currently retrieving data for Kannur: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.296263\n",
      "Currently retrieving data for Kannur: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.594379\n",
      "Currently retrieving data for Kannur: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.860070\n",
      "Currently retrieving data for Kannur: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:07.742985\n",
      "\n",
      "\n",
      "export Kannur completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Kasaragod\n",
      "\n",
      "\n",
      "Currently retrieving data for Kasaragod: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.440909\n",
      "Currently retrieving data for Kasaragod: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.925009\n",
      "Currently retrieving data for Kasaragod: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.504938\n",
      "Currently retrieving data for Kasaragod: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.697641\n",
      "\n",
      "\n",
      "export Kasaragod completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Bhopal\n",
      "\n",
      "\n",
      "Currently retrieving data for Bhopal: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.473355\n",
      "Currently retrieving data for Bhopal: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.784255\n",
      "Currently retrieving data for Bhopal: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.263297\n",
      "Currently retrieving data for Bhopal: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.328711\n",
      "\n",
      "\n",
      "export Bhopal completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Indore\n",
      "\n",
      "\n",
      "Currently retrieving data for Indore: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.240005\n",
      "Currently retrieving data for Indore: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.559388\n",
      "Currently retrieving data for Indore: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.022258\n",
      "Currently retrieving data for Indore: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.464691\n",
      "\n",
      "\n",
      "export Indore completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Mumbai\n",
      "\n",
      "\n",
      "Currently retrieving data for Mumbai: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.655420\n",
      "Currently retrieving data for Mumbai: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.068624\n",
      "Currently retrieving data for Mumbai: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.413842\n",
      "Currently retrieving data for Mumbai: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.295982\n",
      "\n",
      "\n",
      "export Mumbai completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Pune\n",
      "\n",
      "\n",
      "Currently retrieving data for Pune: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.338497\n",
      "Currently retrieving data for Pune: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.546255\n",
      "Currently retrieving data for Pune: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.008404\n",
      "Currently retrieving data for Pune: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.101767\n",
      "\n",
      "\n",
      "export Pune completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Thane\n",
      "\n",
      "\n",
      "Currently retrieving data for Thane: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.281938\n",
      "Currently retrieving data for Thane: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.570737\n",
      "Currently retrieving data for Thane: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.959746\n",
      "Currently retrieving data for Thane: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.828566\n",
      "\n",
      "\n",
      "export Thane completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Jaipur\n",
      "\n",
      "\n",
      "Currently retrieving data for Jaipur: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.264422\n",
      "Currently retrieving data for Jaipur: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.521812\n",
      "Currently retrieving data for Jaipur: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.940746\n",
      "Currently retrieving data for Jaipur: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.923569\n",
      "\n",
      "\n",
      "export Jaipur completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Chennai\n",
      "\n",
      "\n",
      "Currently retrieving data for Chennai: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.049738\n",
      "Currently retrieving data for Chennai: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.251787\n",
      "Currently retrieving data for Chennai: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.859991\n",
      "Currently retrieving data for Chennai: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.752120\n",
      "\n",
      "\n",
      "export Chennai completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Coimbatore\n",
      "\n",
      "\n",
      "Currently retrieving data for Coimbatore: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.477511\n",
      "Currently retrieving data for Coimbatore: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.746149\n",
      "Currently retrieving data for Coimbatore: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.205552\n",
      "Currently retrieving data for Coimbatore: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.766995\n",
      "\n",
      "\n",
      "export Coimbatore completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Erode\n",
      "\n",
      "\n",
      "Currently retrieving data for Erode: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.524112\n",
      "Currently retrieving data for Erode: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.809694\n",
      "Currently retrieving data for Erode: from 2020-03-01 to 2020-03-31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (hh:mm:ss.ms) 0:00:06.423045\n",
      "Currently retrieving data for Erode: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:07.279436\n",
      "\n",
      "\n",
      "export Erode completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Tiruppur\n",
      "\n",
      "\n",
      "Currently retrieving data for Tiruppur: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.758083\n",
      "Currently retrieving data for Tiruppur: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.095647\n",
      "Currently retrieving data for Tiruppur: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.337513\n",
      "Currently retrieving data for Tiruppur: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.208731\n",
      "\n",
      "\n",
      "export Tiruppur completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Hyderabad\n",
      "\n",
      "\n",
      "Currently retrieving data for Hyderabad: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.246492\n",
      "Currently retrieving data for Hyderabad: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.589429\n",
      "Currently retrieving data for Hyderabad: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.024192\n",
      "Currently retrieving data for Hyderabad: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.847117\n",
      "\n",
      "\n",
      "export Hyderabad completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Agra\n",
      "\n",
      "\n",
      "Currently retrieving data for Agra: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.285174\n",
      "Currently retrieving data for Agra: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.758573\n",
      "Currently retrieving data for Agra: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.467906\n",
      "Currently retrieving data for Agra: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:07.829395\n",
      "\n",
      "\n",
      "export Agra completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Delhi\n",
      "\n",
      "\n",
      "Currently retrieving data for Delhi: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.819459\n",
      "Currently retrieving data for Delhi: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:03.553563\n",
      "Currently retrieving data for Delhi: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.205245\n",
      "Currently retrieving data for Delhi: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.310253\n",
      "\n",
      "\n",
      "export Delhi completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Delhi\n",
      "\n",
      "\n",
      "Currently retrieving data for Delhi: from 2020-01-01 to 2020-01-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.000011\n",
      "Currently retrieving data for Delhi: from 2020-02-01 to 2020-02-29\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.017505\n",
      "Currently retrieving data for Delhi: from 2020-03-01 to 2020-03-31\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.536247\n",
      "Currently retrieving data for Delhi: from 2020-04-01 to 2020-04-15\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:05.555506\n",
      "\n",
      "\n",
      "export Delhi completed!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting relevant Temperature and Humidity data\n",
    "# Intialisations\n",
    "\n",
    "os.chdir(r\"C:\\Users\\Sarthak Vishnoi\\TSF-Challenge\\Data\\Weather\")\n",
    "frequency=24\n",
    "start_date = '01-JAN-2020'\n",
    "end_date = '15-APR-2020'\n",
    "api_key = '016c031d9643406991194842200504'\n",
    "# api_key = '764936a7a50e4cb694773340200804'\n",
    "# api_key = '25b608ff66c249a888e104624200804'\n",
    "\n",
    "location_list = districts\n",
    "location_list.append('Delhi')\n",
    "print(location_list)\n",
    "hist_weather_data = retrieve_hist_data(api_key,\n",
    "                                location_list,\n",
    "                                start_date,\n",
    "                                end_date,\n",
    "                                frequency,\n",
    "                                location_label = False,\n",
    "                                export_csv = True,\n",
    "                                store_df = True)\n",
    "os.chdir(r\"C:\\Users\\Sarthak Vishnoi\\TSF-Challenge\\Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosed_date</th>\n",
       "      <th>detected_district</th>\n",
       "      <th>status_change_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>East Delhi</td>\n",
       "      <td>15/03/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/03/2020</td>\n",
       "      <td>South West Delhi</td>\n",
       "      <td>05/03/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/03/2020</td>\n",
       "      <td>Ghaziabad</td>\n",
       "      <td>05/03/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06/03/2020</td>\n",
       "      <td>West Delhi</td>\n",
       "      <td>15/03/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/03/2020</td>\n",
       "      <td>North Delhi</td>\n",
       "      <td>09/03/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>16/04/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16/04/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>16/04/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16/04/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>16/04/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16/04/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>16/04/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16/04/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>16/04/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16/04/2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1814 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosed_date detected_district status_change_date\n",
       "0        02/03/2020        East Delhi         15/03/2020\n",
       "1        05/03/2020  South West Delhi         05/03/2020\n",
       "2        05/03/2020         Ghaziabad         05/03/2020\n",
       "3        06/03/2020        West Delhi         15/03/2020\n",
       "4        09/03/2020       North Delhi         09/03/2020\n",
       "...             ...               ...                ...\n",
       "1809     16/04/2020               NaN         16/04/2020\n",
       "1810     16/04/2020               NaN         16/04/2020\n",
       "1811     16/04/2020               NaN         16/04/2020\n",
       "1812     16/04/2020               NaN         16/04/2020\n",
       "1813     16/04/2020               NaN         16/04/2020\n",
       "\n",
       "[1814 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing the analysis for all the districts\n",
    "# Collecting the districts\n",
    "districtData = data1.drop(['id', 'nationality'], axis=1)\n",
    "delhiData = data1.drop(['id', 'nationality'], axis=1)\n",
    "\n",
    "for index,row in districtData.iterrows():\n",
    "    if(not(row['detected_district'] in districts)):\n",
    "        districtData.drop(index, inplace=True)\n",
    "districtData.reset_index(inplace = True, drop = True)\n",
    "districtData = districtData.drop(['government_id', 'age', 'gender', 'detected_city', 'detected_state', 'notes'], axis=1)\n",
    "districtData\n",
    "\n",
    "# For Delhi\n",
    "for index,row in delhiData.iterrows():\n",
    "    if((not(row['detected_district'] in delhi)) and (not(row['detected_state'] in delhiState))):\n",
    "        delhiData.drop(index, inplace=True)\n",
    "delhiData.reset_index(inplace = True, drop = True)\n",
    "delhiData = delhiData.drop(['government_id', 'age', 'gender', 'detected_city', 'detected_state', 'notes'], axis=1)\n",
    "delhiData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guntur\n",
      "Kurnool\n",
      "Ahmadabad\n",
      "Vadodara\n",
      "Bengaluru\n",
      "Kannur\n",
      "Kasaragod\n",
      "Bhopal\n",
      "Indore\n",
      "Mumbai\n",
      "Pune\n",
      "Thane\n",
      "Jaipur\n",
      "Chennai\n",
      "Coimbatore\n",
      "Erode\n",
      "Tiruppur\n",
      "Hyderabad\n",
      "Agra\n",
      "Delhi\n",
      "Delhi\n"
     ]
    }
   ],
   "source": [
    "# Making time series data for each district. Temperature and Humidity will be added to this, also, lockdown. \n",
    "# We don't need notes as it is individual level data\n",
    "# Status change date will help us with recovered and died cases.\n",
    "# districtCols1 = ['diagnosed_date', 'detected_district', 'current_status', 'status_change_date']\n",
    "dates = []\n",
    "districtCols = ['NewCases', 'Lockdown'] \n",
    "districtRHCols = ['Temp_0', 'Temp_1', 'Temp_2', 'Temp_3', 'Temp_4', 'Temp_5', 'Temp_6', 'Temp_7',\n",
    "       'Temp_8', 'Temp_9', 'Temp_10', 'Temp_11', 'Temp_12', 'Temp_13',\n",
    "       'Temp_14', 'RH_0', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6',\n",
    "       'RH_7', 'RH_8', 'RH_9', 'RH_10', 'RH_11', 'RH_12', 'RH_13', 'RH_14']\n",
    "\n",
    "lockdown_date_str = \"25-03-2020\"\n",
    "lockdown_date_obj = datetime.strptime(lockdown_date_str, '%d-%m-%Y').date()\n",
    "start_date_str = \"30-01-2020\"\n",
    "start_date_obj = datetime.strptime(start_date_str, '%d-%m-%Y').date()\n",
    "end_date_str = \"15-04-2020\"\n",
    "end_date_obj = datetime.strptime(end_date_str, '%d-%m-%Y').date()\n",
    "# Total 70 days\n",
    "days = 77\n",
    "for district in districts:\n",
    "    print(district)\n",
    "    distCases = np.zeros([days,2])\n",
    "    distRH = np.zeros([days,30])\n",
    "    index = 0\n",
    "    dates = []\n",
    "    for dt in daterange(start_date_obj, end_date_obj):\n",
    "        currDate = dt.strftime(\"%d-%m-%Y\")\n",
    "        currDateObj = datetime.strptime(currDate, '%d-%m-%Y').date()\n",
    "#         Adding current date\n",
    "        dates.append(currDate)\n",
    "        newCases = 0\n",
    "        recovered = 0\n",
    "        died = 0\n",
    "        lockdown = 0\n",
    "        if(currDateObj >= lockdown_date_obj):\n",
    "            lockdown += 1\n",
    "#       For dist Cases\n",
    "        for _,row in districtData.iterrows():\n",
    "            if(row['detected_district'] == district):\n",
    "                checkDateObj = datetime.strptime(row['diagnosed_date'], '%d/%m/%Y').date()\n",
    "                if(currDateObj == checkDateObj):\n",
    "                    newCases += 1\n",
    "#                 if(isinstance(row['status_change_date'], str)):\n",
    "#                     statusDateObj = datetime.strptime(row['status_change_date'], '%d-%m-%Y').date()\n",
    "#                     if(currDateObj == statusDateObj):\n",
    "#                         if(row['current_status'] == 'Recovered'):\n",
    "#                             recovered += 1\n",
    "#                         elif(row['current_status'] == 'Deceased'):\n",
    "#                             died += 1\n",
    "        distCases[index,0] = newCases\n",
    "#         distCases[index,1] = recovered\n",
    "#         distCases[index,2] = died\n",
    "        distCases[index,1] = lockdown\n",
    "#       For RH and Temp\n",
    "        if((district in diffDist)):\n",
    "            nameDist = diffDist[district]\n",
    "        else:\n",
    "            nameDist = district\n",
    "        tempData = pd.read_csv('./Weather/' + nameDist + '.csv')\n",
    "        for index_,row_ in tempData.iterrows():\n",
    "            date_str2 = row_['date_time']\n",
    "            tempDateObj = datetime.strptime(date_str2, '%Y-%m-%d').date()\n",
    "            if(currDateObj == tempDateObj):\n",
    "                for i in range(15):\n",
    "                    distRH[index,i] = tempData['FeelsLikeC'][index_-i]\n",
    "                    distRH[index,i+15] = tempData['humidity'][index_-i]\n",
    "        index += 1\n",
    "        \n",
    "#       Saving this CSV file\n",
    "        datesDF = pd.DataFrame(data=dates, columns=['Date'])\n",
    "        distCasesDF = pd.DataFrame(data=distCases, columns=districtCols)\n",
    "        distRHDF = pd.DataFrame(data=distRH, columns=districtRHCols)\n",
    "        districtDF = pd.concat([datesDF, distCasesDF, distRHDF], axis=1, sort=False)\n",
    "        districtDF.to_csv('./Districts/' + nameDist + '.csv',index=False)\n",
    "    \n",
    "    \n",
    "# #     First start with making a dataframe for each district\n",
    "#     districtDF = pd.DataFrame(columns=districtCols1)\n",
    "#     for index,row in districtData.iterrows():\n",
    "#         if(row['detected_district'] == district):\n",
    "#             districtDF = districtDF.append(districtData.iloc[index,:], ignore_index=True)\n",
    "#     numRows = districtDF.shape[0]\n",
    "# #     Getting the new number of cases and making an np array for other details    \n",
    "#     districtTimeSeriesData = np.zeros([numRows, 4])\n",
    "#     districtRHData = np.zeros([numRows, 30])\n",
    "# #     print(districtDF)\n",
    "# #     Assume data is in ascending order of dates\n",
    "#     for counter1 in range(numRows):\n",
    "#         date_obj1 = datetime.strptime(str(districtDF['diagnosed_date'][counter1]), '%d-%m-%Y').date()\n",
    "#         count = 0\n",
    "#         for counter2 in range(numRows):\n",
    "#             date_obj2 = datetime.strptime(districtDF['diagnosed_date'][counter2], '%d-%m-%Y').date()\n",
    "#             if(date_obj1 == date_obj2):\n",
    "#                 count += 1\n",
    "#             elif(date_obj1 < date_obj2):\n",
    "#                 break\n",
    "#         districtTimeSeriesData[counter1,0] = count\n",
    "# #     for recovered and deceased\n",
    "#     for counter1 in range(numRows):\n",
    "#         date_obj1 = datetime.strptime(districtDF['diagnosed_date'][counter1], '%d-%m-%Y').date()\n",
    "# #         Lockdown\n",
    "#         if(date_obj1 >= lockdown_date_obj):\n",
    "#             districtTimeSeriesData[counter1, 3] = 1\n",
    "#         recovered = 0\n",
    "#         died = 0\n",
    "#         for counter2 in range(numRows):\n",
    "#             if(isinstance(districtDF['status_change_date'][counter2], float)):\n",
    "#                 continue\n",
    "#             date_obj2 = datetime.strptime(districtDF['status_change_date'][counter2], '%d-%m-%Y').date()\n",
    "#             if(date_obj1 == date_obj2):\n",
    "#                 if(districtDF['current_status'][counter2] == 'Recovered'):\n",
    "#                     recovered += 1\n",
    "#                 elif(districtDF['current_status'][counter2] == 'Deceased'):\n",
    "#                     died += 1\n",
    "#         districtTimeSeriesData[counter1, 1] = recovered\n",
    "#         districtTimeSeriesData[counter1, 2] = died\n",
    "# #     RH Data\n",
    "    \n",
    "#     if((district in diffDist)):\n",
    "#         nameDist = diffDist[district]\n",
    "#     else:\n",
    "#         nameDist = district\n",
    "    \n",
    "#     tempData = pd.read_csv('./Weather/' + nameDist + '.csv')\n",
    "#     print(numRows)\n",
    "#     for index in range(numRows):\n",
    "#         date_obj1 = datetime.strptime(districtDF['diagnosed_date'][index], '%d-%m-%Y').date()\n",
    "#         for index_,row_ in tempData.iterrows():\n",
    "#             date_str2 = row_['date_time']\n",
    "#             date_object2 = datetime.strptime(date_str2, '%Y-%m-%d').date()\n",
    "#             if(date_obj1 == date_object2):\n",
    "#                 for i in range(15):\n",
    "#                     districtRHData[index,i] = tempData['FeelsLikeC'][index_-i]\n",
    "#                     districtRHData[index,i+15] = tempData['humidity'][index_-i]\n",
    "# #     Making a big dataframe\n",
    "#     districtRHDF = pd.DataFrame(data=districtRHData, columns=districtRH)\n",
    "#     districtTimeSeriesDF = pd.DataFrame(data=districtTimeSeriesData, columns=districtCols2)\n",
    "#     district_DF = pd.concat([districtDF, districtTimeSeriesDF, districtRHDF], axis=1, sort=False)\n",
    "#     finalCSVcols = district_DF.columns\n",
    "    \n",
    "# #     Make the data like a time series and not like individual details\n",
    "#     for dt in daterange(start_date_obj, end_date_obj):\n",
    "#         for index,row in district_DF.iterrows():\n",
    "# #     district_DF.to_csv('./Districts/' + nameDist + '.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing this for Delhi, not a duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making time series data for each district. Temperature and Humidity will be added to this, also, lockdown. \n",
    "# We don't need notes as it is individual level data\n",
    "# Status change date will help us with recovered and died cases.\n",
    "# districtCols1 = ['diagnosed_date', 'detected_district', 'current_status', 'status_change_date']\n",
    "dates = []\n",
    "districtCols = ['NewCases', 'Lockdown'] \n",
    "districtRHCols = ['Temp_0', 'Temp_1', 'Temp_2', 'Temp_3', 'Temp_4', 'Temp_5', 'Temp_6', 'Temp_7',\n",
    "       'Temp_8', 'Temp_9', 'Temp_10', 'Temp_11', 'Temp_12', 'Temp_13',\n",
    "       'Temp_14', 'RH_0', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6',\n",
    "       'RH_7', 'RH_8', 'RH_9', 'RH_10', 'RH_11', 'RH_12', 'RH_13', 'RH_14']\n",
    "\n",
    "# lockdown_date_str = \"25-03-2020\"\n",
    "# lockdown_date_obj = datetime.strptime(lockdown_date_str, '%d-%m-%Y').date()\n",
    "# start_date_str = \"30-01-2020\"\n",
    "# start_date_obj = datetime.strptime(start_date_str, '%d-%m-%Y').date()\n",
    "# end_date_str = \"08-04-2020\"\n",
    "# end_date_obj = datetime.strptime(end_date_str, '%d-%m-%Y').date()\n",
    "# Total 74 days\n",
    "# days = 70\n",
    "distCases = np.zeros([days,2])\n",
    "distRH = np.zeros([days,30])\n",
    "index = 0\n",
    "   \n",
    "for dt in daterange(start_date_obj, end_date_obj):\n",
    "    currDate = dt.strftime(\"%d-%m-%Y\")\n",
    "    currDateObj = datetime.strptime(currDate, '%d-%m-%Y').date()\n",
    "#   Adding current date\n",
    "    dates.append(currDate)\n",
    "    newCases = 0\n",
    "    recovered = 0\n",
    "    died = 0\n",
    "    lockdown = 0\n",
    "    if(currDateObj >= lockdown_date_obj):\n",
    "        lockdown += 1\n",
    "#   For dist Cases\n",
    "    for _,row in districtData.iterrows():\n",
    "        checkDateObj = datetime.strptime(row['diagnosed_date'], '%d/%m/%Y').date()\n",
    "        if(currDateObj == checkDateObj):\n",
    "            newCases += 1\n",
    "#         if(isinstance(row['status_change_date'], str)):\n",
    "#             statusDateObj = datetime.strptime(row['status_change_date'], '%d-%m-%Y').date()\n",
    "#             if(currDateObj == statusDateObj):\n",
    "#                 if(row['current_status'] == 'Recovered'):\n",
    "#                     recovered += 1\n",
    "#                 elif(row['current_status'] == 'Deceased'):\n",
    "#                     died += 1\n",
    "    distCases[index,0] = newCases\n",
    "#     distCases[index,1] = recovered\n",
    "#     distCases[index,2] = died\n",
    "    distCases[index,1] = lockdown\n",
    "#   For RH and Temp\n",
    "    nameDist = 'Delhi'\n",
    "    tempData = pd.read_csv('./Weather/' + nameDist + '.csv')\n",
    "    for index_,row_ in tempData.iterrows():\n",
    "        date_str2 = row_['date_time']\n",
    "        tempDateObj = datetime.strptime(date_str2, '%Y-%m-%d').date()\n",
    "        if(currDateObj == tempDateObj):\n",
    "            for i in range(15):\n",
    "                distRH[index,i] = tempData['FeelsLikeC'][index_-i]\n",
    "                distRH[index,i+15] = tempData['humidity'][index_-i]\n",
    "    index += 1\n",
    "\n",
    "#   Saving this CSV file\n",
    "    datesDF = pd.DataFrame(data=dates, columns=['Date'])\n",
    "    distCasesDF = pd.DataFrame(data=distCases, columns=districtCols)\n",
    "    distRHDF = pd.DataFrame(data=distRH, columns=districtRHCols)\n",
    "    districtDF = pd.concat([datesDF, distCasesDF, distRHDF], axis=1, sort=False)\n",
    "    districtDF.to_csv('./Districts/' + nameDist + '.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Guntur', 'Kurnool', 'Ahmadabad', 'Vadodara', 'Bengaluru', 'Kannur', 'Kasaragod', 'Bhopal', 'Indore', 'Mumbai', 'Pune', 'Thane', 'Jaipur', 'Chennai', 'Coimbatore', 'Erode', 'Tiruppur', 'Hyderabad', 'Agra', 'Delhi', 'Delhi', 'Delhi']\n",
      "\n",
      "\n",
      "Retrieving weather data for Guntur\n",
      "\n",
      "\n",
      "Currently retrieving data for Guntur: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:02.943052\n",
      "\n",
      "\n",
      "export Guntur completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Kurnool\n",
      "\n",
      "\n",
      "Currently retrieving data for Kurnool: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.537549\n",
      "\n",
      "\n",
      "export Kurnool completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Ahmadabad\n",
      "\n",
      "\n",
      "Currently retrieving data for Ahmadabad: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.562190\n",
      "\n",
      "\n",
      "export Ahmadabad completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Vadodara\n",
      "\n",
      "\n",
      "Currently retrieving data for Vadodara: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.579360\n",
      "\n",
      "\n",
      "export Vadodara completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Bengaluru\n",
      "\n",
      "\n",
      "Currently retrieving data for Bengaluru: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.596425\n",
      "\n",
      "\n",
      "export Bengaluru completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Kannur\n",
      "\n",
      "\n",
      "Currently retrieving data for Kannur: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.589103\n",
      "\n",
      "\n",
      "export Kannur completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Kasaragod\n",
      "\n",
      "\n",
      "Currently retrieving data for Kasaragod: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.568034\n",
      "\n",
      "\n",
      "export Kasaragod completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Bhopal\n",
      "\n",
      "\n",
      "Currently retrieving data for Bhopal: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.607272\n",
      "\n",
      "\n",
      "export Bhopal completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Indore\n",
      "\n",
      "\n",
      "Currently retrieving data for Indore: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.635949\n",
      "\n",
      "\n",
      "export Indore completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Mumbai\n",
      "\n",
      "\n",
      "Currently retrieving data for Mumbai: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.596957\n",
      "\n",
      "\n",
      "export Mumbai completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Pune\n",
      "\n",
      "\n",
      "Currently retrieving data for Pune: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.555134\n",
      "\n",
      "\n",
      "export Pune completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Thane\n",
      "\n",
      "\n",
      "Currently retrieving data for Thane: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.652922\n",
      "\n",
      "\n",
      "export Thane completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Jaipur\n",
      "\n",
      "\n",
      "Currently retrieving data for Jaipur: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.527414\n",
      "\n",
      "\n",
      "export Jaipur completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Chennai\n",
      "\n",
      "\n",
      "Currently retrieving data for Chennai: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.605694\n",
      "\n",
      "\n",
      "export Chennai completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Coimbatore\n",
      "\n",
      "\n",
      "Currently retrieving data for Coimbatore: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.599680\n",
      "\n",
      "\n",
      "export Coimbatore completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Erode\n",
      "\n",
      "\n",
      "Currently retrieving data for Erode: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.562653\n",
      "\n",
      "\n",
      "export Erode completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Tiruppur\n",
      "\n",
      "\n",
      "Currently retrieving data for Tiruppur: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.547461\n",
      "\n",
      "\n",
      "export Tiruppur completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Hyderabad\n",
      "\n",
      "\n",
      "Currently retrieving data for Hyderabad: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.551286\n",
      "\n",
      "\n",
      "export Hyderabad completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Agra\n",
      "\n",
      "\n",
      "Currently retrieving data for Agra: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.555052\n",
      "\n",
      "\n",
      "export Agra completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Delhi\n",
      "\n",
      "\n",
      "Currently retrieving data for Delhi: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.568894\n",
      "\n",
      "\n",
      "export Delhi completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Delhi\n",
      "\n",
      "\n",
      "Currently retrieving data for Delhi: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.552330\n",
      "\n",
      "\n",
      "export Delhi completed!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieving weather data for Delhi\n",
      "\n",
      "\n",
      "Currently retrieving data for Delhi: from 2020-04-16 to 2020-04-17\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.562615\n",
      "\n",
      "\n",
      "export Delhi completed!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Data\n",
    "\n",
    "os.chdir(r\"C:\\Users\\Sarthak Vishnoi\\TSF-Challenge\\Data\\Districts\\Test\")\n",
    "frequency=24\n",
    "start_date = '16-APR-2020'\n",
    "end_date = '17-APR-2020'\n",
    "api_key = '016c031d9643406991194842200504'\n",
    "# api_key = '764936a7a50e4cb694773340200804'\n",
    "# api_key = '25b608ff66c249a888e104624200804'\n",
    "\n",
    "location_list = districts\n",
    "location_list.append('Delhi')\n",
    "print(location_list)\n",
    "hist_weather_data = retrieve_hist_data(api_key,\n",
    "                                location_list,\n",
    "                                start_date,\n",
    "                                end_date,\n",
    "                                frequency,\n",
    "                                location_label = False,\n",
    "                                export_csv = True,\n",
    "                                store_df = True)\n",
    "os.chdir(r\"C:\\Users\\Sarthak Vishnoi\\TSF-Challenge\\Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
